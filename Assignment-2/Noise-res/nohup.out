2020-11-16 13:08:04.205051: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-11-16 13:08:04.212574: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2345480000 Hz
2020-11-16 13:08:04.214087: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x565277a4de80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-11-16 13:08:04.214103: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
full data
[SAVED TO all_outputs.txt] Saved Figure as "[1]full_data_plot.pdf"
train data
[SAVED TO all_outputs.txt] Saved Figure as "[2]train_data_plot.pdf"
test data
[SAVED TO all_outputs.txt] Saved Figure as "[3]test_data_plot.pdf"
[SAVED TO all_outputs.txt] Changed Parameters: NOISE->0.5
full data
[SAVED TO all_outputs.txt] Saved Figure as "[4]full_data_plot.pdf"
train data
[SAVED TO all_outputs.txt] Saved Figure as "[5]train_data_plot.pdf"
test data
[SAVED TO all_outputs.txt] Saved Figure as "[6]test_data_plot.pdf"
[SAVED TO all_outputs.txt] ARGS:  {'population_size': 30, 'time_steps': 1000, 'averaging': 100}
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense (Dense)                (500, 8)                  40        
_________________________________________________________________
re_lu (ReLU)                 (500, 8)                  0         
_________________________________________________________________
dense_1 (Dense)              (500, 1)                  9         
=================================================================
Total params: 49
Trainable params: 49
Non-trainable params: 0
_________________________________________________________________
[SAVED TO all_outputs.txt] Gradient Descent 1 Training for 1000 Epochs with 30 per Batch
1/8 [==>...........................] - ETA: 0s - loss: 0.6825 - accuracy: 0.50008/8 [==============================] - 0s 394us/step - loss: 0.6392 - accuracy: 0.6080
Model 0: [0.6391984820365906, 0.6079999804496765]
1/8 [==>...........................] - ETA: 0s - loss: 0.6604 - accuracy: 0.56258/8 [==============================] - 0s 314us/step - loss: 0.6215 - accuracy: 0.6520
Model 1: [0.6215094327926636, 0.6520000100135803]
1/8 [==>...........................] - ETA: 0s - loss: 0.6402 - accuracy: 0.59388/8 [==============================] - 0s 350us/step - loss: 0.6106 - accuracy: 0.6760
Model 2: [0.6105590462684631, 0.6759999990463257]
1/8 [==>...........................] - ETA: 0s - loss: 0.6227 - accuracy: 0.65628/8 [==============================] - 0s 337us/step - loss: 0.5911 - accuracy: 0.7280
Model 3: [0.591107964515686, 0.7279999852180481]
1/8 [==>...........................] - ETA: 0s - loss: 0.4899 - accuracy: 0.87508/8 [==============================] - 0s 312us/step - loss: 0.5279 - accuracy: 0.8360
Model 4: [0.5278837084770203, 0.8360000252723694]
1/8 [==>...........................] - ETA: 0s - loss: 0.4625 - accuracy: 0.84388/8 [==============================] - 0s 311us/step - loss: 0.5068 - accuracy: 0.8520
Model 5: [0.5068293809890747, 0.8519999980926514]
1/8 [==>...........................] - ETA: 0s - loss: 0.4368 - accuracy: 0.87508/8 [==============================] - 0s 331us/step - loss: 0.4881 - accuracy: 0.8640
Model 6: [0.4881209135055542, 0.8640000224113464]
1/8 [==>...........................] - ETA: 0s - loss: 0.4294 - accuracy: 0.87508/8 [==============================] - 0s 334us/step - loss: 0.4833 - accuracy: 0.8720
Model 7: [0.48327913880348206, 0.871999979019165]
1/8 [==>...........................] - ETA: 0s - loss: 0.3829 - accuracy: 0.90628/8 [==============================] - 0s 309us/step - loss: 0.4456 - accuracy: 0.8920
Model 8: [0.44559183716773987, 0.8920000195503235]
1/8 [==>...........................] - ETA: 0s - loss: 0.3614 - accuracy: 0.93758/8 [==============================] - 0s 339us/step - loss: 0.4396 - accuracy: 0.8920
Model 9: [0.439575731754303, 0.8920000195503235]
1/8 [==>...........................] - ETA: 0s - loss: 0.3547 - accuracy: 0.93758/8 [==============================] - 0s 295us/step - loss: 0.4377 - accuracy: 0.8920
Model 10: [0.43771377205848694, 0.8920000195503235]
1/8 [==>...........................] - ETA: 0s - loss: 0.3504 - accuracy: 0.93758/8 [==============================] - 0s 300us/step - loss: 0.4365 - accuracy: 0.8800
Model 11: [0.43648141622543335, 0.8799999952316284]
1/8 [==>...........................] - ETA: 0s - loss: 0.3472 - accuracy: 0.93758/8 [==============================] - 0s 308us/step - loss: 0.4360 - accuracy: 0.8800
Model 12: [0.4360406994819641, 0.8799999952316284]
1/8 [==>...........................] - ETA: 0s - loss: 0.3443 - accuracy: 0.93758/8 [==============================] - 0s 312us/step - loss: 0.4356 - accuracy: 0.8840
Model 13: [0.43564867973327637, 0.8840000033378601]
1/8 [==>...........................] - ETA: 0s - loss: 0.3461 - accuracy: 0.93758/8 [==============================] - 0s 287us/step - loss: 0.4355 - accuracy: 0.8840
Model 14: [0.4354996383190155, 0.8840000033378601]
1/8 [==>...........................] - ETA: 0s - loss: 0.3440 - accuracy: 0.90628/8 [==============================] - 0s 303us/step - loss: 0.4355 - accuracy: 0.8840
Model 15: [0.43552374839782715, 0.8840000033378601]
1/8 [==>...........................] - ETA: 0s - loss: 0.3426 - accuracy: 0.93758/8 [==============================] - 0s 284us/step - loss: 0.4355 - accuracy: 0.8800
Model 16: [0.43547606468200684, 0.8799999952316284]
1/8 [==>...........................] - ETA: 0s - loss: 0.3384 - accuracy: 0.93758/8 [==============================] - 0s 350us/step - loss: 0.4353 - accuracy: 0.8760
Model 17: [0.43530699610710144, 0.8759999871253967]
1/8 [==>...........................] - ETA: 0s - loss: 0.3394 - accuracy: 0.93758/8 [==============================] - 0s 292us/step - loss: 0.4351 - accuracy: 0.8760
Model 18: [0.435110479593277, 0.8759999871253967]
1/8 [==>...........................] - ETA: 0s - loss: 0.3413 - accuracy: 0.93758/8 [==============================] - 0s 284us/step - loss: 0.4352 - accuracy: 0.8840
Model 19: [0.43517592549324036, 0.8840000033378601]
1/8 [==>...........................] - ETA: 0s - loss: 0.3376 - accuracy: 0.93758/8 [==============================] - 0s 288us/step - loss: 0.4356 - accuracy: 0.8760
Model 20: [0.43559470772743225, 0.8759999871253967]
1/8 [==>...........................] - ETA: 0s - loss: 0.3411 - accuracy: 0.93758/8 [==============================] - 0s 278us/step - loss: 0.4351 - accuracy: 0.8800
Model 21: [0.43514034152030945, 0.8799999952316284]
1/8 [==>...........................] - ETA: 0s - loss: 0.3402 - accuracy: 0.93758/8 [==============================] - 0s 284us/step - loss: 0.4351 - accuracy: 0.8840
Model 22: [0.4350624084472656, 0.8840000033378601]
1/8 [==>...........................] - ETA: 0s - loss: 0.3388 - accuracy: 0.93758/8 [==============================] - 0s 295us/step - loss: 0.4351 - accuracy: 0.8840
Model 23: [0.4351244866847992, 0.8840000033378601]
1/8 [==>...........................] - ETA: 0s - loss: 0.3467 - accuracy: 0.90628/8 [==============================] - 0s 288us/step - loss: 0.4355 - accuracy: 0.8840
Model 24: [0.4354766309261322, 0.8840000033378601]
1/8 [==>...........................] - ETA: 0s - loss: 0.3393 - accuracy: 0.93758/8 [==============================] - 0s 272us/step - loss: 0.4351 - accuracy: 0.8840
Model 25: [0.43510761857032776, 0.8840000033378601]
1/8 [==>...........................] - ETA: 0s - loss: 0.3422 - accuracy: 0.93758/8 [==============================] - 0s 288us/step - loss: 0.4355 - accuracy: 0.8880
Model 26: [0.43547430634498596, 0.8880000114440918]
1/8 [==>...........................] - ETA: 0s - loss: 0.3360 - accuracy: 0.93758/8 [==============================] - 0s 283us/step - loss: 0.4354 - accuracy: 0.8840
Model 27: [0.43542349338531494, 0.8840000033378601]
1/8 [==>...........................] - ETA: 0s - loss: 0.3387 - accuracy: 0.93758/8 [==============================] - 0s 283us/step - loss: 0.4355 - accuracy: 0.8800
Model 28: [0.4354678690433502, 0.8799999952316284]
1/8 [==>...........................] - ETA: 0s - loss: 0.3379 - accuracy: 0.93758/8 [==============================] - 0s 271us/step - loss: 0.4354 - accuracy: 0.8760
Model 29: [0.435392826795578, 0.8759999871253967]
1/8 [==>...........................] - ETA: 0s - loss: 0.3381 - accuracy: 0.93758/8 [==============================] - 0s 298us/step - loss: 0.4351 - accuracy: 0.8760
Model 30: [0.43505388498306274, 0.8759999871253967]
1/8 [==>...........................] - ETA: 0s - loss: 0.3402 - accuracy: 0.93758/8 [==============================] - 0s 271us/step - loss: 0.4352 - accuracy: 0.8800
Model 31: [0.43516024947166443, 0.8799999952316284]
1/8 [==>...........................] - ETA: 0s - loss: 0.3395 - accuracy: 0.93758/8 [==============================] - 0s 288us/step - loss: 0.4351 - accuracy: 0.8840
Model 32: [0.43512001633644104, 0.8840000033378601]
1/8 [==>...........................] - ETA: 0s - loss: 0.3413 - accuracy: 0.93758/8 [==============================] - 0s 284us/step - loss: 0.4354 - accuracy: 0.8800
Model 33: [0.43541663885116577, 0.8799999952316284]
1/8 [==>...........................] - ETA: 0s - loss: 0.3417 - accuracy: 0.93758/8 [==============================] - 0s 292us/step - loss: 0.4351 - accuracy: 0.8840
Model 34: [0.4350515305995941, 0.8840000033378601]
1/8 [==>...........................] - ETA: 0s - loss: 0.3390 - accuracy: 0.93758/8 [==============================] - 0s 279us/step - loss: 0.4352 - accuracy: 0.8800
Model 35: [0.43518465757369995, 0.8799999952316284]
1/8 [==>...........................] - ETA: 0s - loss: 0.3383 - accuracy: 0.93758/8 [==============================] - 0s 273us/step - loss: 0.4350 - accuracy: 0.8800
Model 36: [0.43504688143730164, 0.8799999952316284]
1/8 [==>...........................] - ETA: 0s - loss: 0.3367 - accuracy: 0.93758/8 [==============================] - 0s 269us/step - loss: 0.4354 - accuracy: 0.8840
Model 37: [0.4354090094566345, 0.8840000033378601]
1/8 [==>...........................] - ETA: 0s - loss: 0.3416 - accuracy: 0.93758/8 [==============================] - 0s 288us/step - loss: 0.4351 - accuracy: 0.8840
Model 38: [0.4351412057876587, 0.8840000033378601]
1/8 [==>...........................] - ETA: 0s - loss: 0.3405 - accuracy: 0.93758/8 [==============================] - 0s 267us/step - loss: 0.4351 - accuracy: 0.8800
Model 39: [0.4350557029247284, 0.8799999952316284]
1/8 [==>...........................] - ETA: 0s - loss: 0.3397 - accuracy: 0.93758/8 [==============================] - 0s 286us/step - loss: 0.4353 - accuracy: 0.8800
Model 40: [0.4352528750896454, 0.8799999952316284]
1/8 [==>...........................] - ETA: 0s - loss: 0.3364 - accuracy: 0.93758/8 [==============================] - 0s 269us/step - loss: 0.4353 - accuracy: 0.8800
Model 41: [0.4353463351726532, 0.8799999952316284]
1/8 [==>...........................] - ETA: 0s - loss: 0.3403 - accuracy: 0.93758/8 [==============================] - 0s 329us/step - loss: 0.4354 - accuracy: 0.8840
Model 42: [0.43536725640296936, 0.8840000033378601]
1/8 [==>...........................] - ETA: 0s - loss: 0.3406 - accuracy: 0.93758/8 [==============================] - 0s 268us/step - loss: 0.4353 - accuracy: 0.8880
Model 43: [0.4352644383907318, 0.8880000114440918]
1/8 [==>...........................] - ETA: 0s - loss: 0.3398 - accuracy: 0.93758/8 [==============================] - 0s 267us/step - loss: 0.4351 - accuracy: 0.8800
Model 44: [0.4351097345352173, 0.8799999952316284]
1/8 [==>...........................] - ETA: 0s - loss: 0.3423 - accuracy: 0.93758/8 [==============================] - 0s 270us/step - loss: 0.4352 - accuracy: 0.8840
Model 45: [0.43516337871551514, 0.8840000033378601]
1/8 [==>...........................] - ETA: 0s - loss: 0.3402 - accuracy: 0.93758/8 [==============================] - 0s 277us/step - loss: 0.4354 - accuracy: 0.8760
Model 46: [0.4353784918785095, 0.8759999871253967]
1/8 [==>...........................] - ETA: 0s - loss: 0.3402 - accuracy: 0.93758/8 [==============================] - 0s 295us/step - loss: 0.4350 - accuracy: 0.8800
Model 47: [0.43497562408447266, 0.8799999952316284]
1/8 [==>...........................] - ETA: 0s - loss: 0.3438 - accuracy: 0.93758/8 [==============================] - 0s 287us/step - loss: 0.4351 - accuracy: 0.8840
Model 48: [0.43510812520980835, 0.8840000033378601]
1/8 [==>...........................] - ETA: 0s - loss: 0.3447 - accuracy: 0.93758/8 [==============================] - 0s 288us/step - loss: 0.4352 - accuracy: 0.8920
Model 49: [0.4352434277534485, 0.8920000195503235]
1/8 [==>...........................] - ETA: 0s - loss: 0.3363 - accuracy: 0.93758/8 [==============================] - 0s 289us/step - loss: 0.4352 - accuracy: 0.8840
Model 50: [0.4351845681667328, 0.8840000033378601]
1/8 [==>...........................] - ETA: 0s - loss: 0.3419 - accuracy: 0.90628/8 [==============================] - 0s 266us/step - loss: 0.4356 - accuracy: 0.8800
Model 51: [0.43556931614875793, 0.8799999952316284]
1/8 [==>...........................] - ETA: 0s - loss: 0.3388 - accuracy: 0.93758/8 [==============================] - 0s 295us/step - loss: 0.4351 - accuracy: 0.8760
Model 52: [0.4350913166999817, 0.8759999871253967]
1/8 [==>...........................] - ETA: 0s - loss: 0.3430 - accuracy: 0.90628/8 [==============================] - 0s 283us/step - loss: 0.4358 - accuracy: 0.8840
Model 53: [0.43578773736953735, 0.8840000033378601]
1/8 [==>...........................] - ETA: 0s - loss: 0.3411 - accuracy: 0.93758/8 [==============================] - 0s 292us/step - loss: 0.4351 - accuracy: 0.8840
Model 54: [0.43508702516555786, 0.8840000033378601]
1/8 [==>...........................] - ETA: 0s - loss: 0.3441 - accuracy: 0.90628/8 [==============================] - 0s 276us/step - loss: 0.4357 - accuracy: 0.8840
Model 55: [0.4356592297554016, 0.8840000033378601]
1/8 [==>...........................] - ETA: 0s - loss: 0.3404 - accuracy: 0.93758/8 [==============================] - 0s 277us/step - loss: 0.4353 - accuracy: 0.8760
Model 56: [0.4352567493915558, 0.8759999871253967]
1/8 [==>...........................] - ETA: 0s - loss: 0.3430 - accuracy: 0.93758/8 [==============================] - 0s 277us/step - loss: 0.4354 - accuracy: 0.8880
Model 57: [0.43544691801071167, 0.8880000114440918]
1/8 [==>...........................] - ETA: 0s - loss: 0.3368 - accuracy: 0.93758/8 [==============================] - 0s 276us/step - loss: 0.4351 - accuracy: 0.8800
Model 58: [0.4351450204849243, 0.8799999952316284]
1/8 [==>...........................] - ETA: 0s - loss: 0.3371 - accuracy: 0.93758/8 [==============================] - 0s 298us/step - loss: 0.4355 - accuracy: 0.8840
Model 59: [0.43551066517829895, 0.8840000033378601]
1/8 [==>...........................] - ETA: 0s - loss: 0.3381 - accuracy: 0.93758/8 [==============================] - 0s 290us/step - loss: 0.4353 - accuracy: 0.8800
Model 60: [0.4352935552597046, 0.8799999952316284]
1/8 [==>...........................] - ETA: 0s - loss: 0.3371 - accuracy: 0.93758/8 [==============================] - 0s 280us/step - loss: 0.4356 - accuracy: 0.8800
Model 61: [0.4356347918510437, 0.8799999952316284]
1/8 [==>...........................] - ETA: 0s - loss: 0.3383 - accuracy: 0.93758/8 [==============================] - 0s 280us/step - loss: 0.4351 - accuracy: 0.8800
Model 62: [0.43505653738975525, 0.8799999952316284]
1/8 [==>...........................] - ETA: 0s - loss: 0.3407 - accuracy: 0.93758/8 [==============================] - 0s 278us/step - loss: 0.4352 - accuracy: 0.8840
Model 63: [0.4351598918437958, 0.8840000033378601]
1/8 [==>...........................] - ETA: 0s - loss: 0.3385 - accuracy: 0.93758/8 [==============================] - 0s 262us/step - loss: 0.4353 - accuracy: 0.8800
Model 64: [0.43527519702911377, 0.8799999952316284]
1/8 [==>...........................] - ETA: 0s - loss: 0.3383 - accuracy: 0.93758/8 [==============================] - 0s 282us/step - loss: 0.4351 - accuracy: 0.8800
Model 65: [0.43510356545448303, 0.8799999952316284]
1/8 [==>...........................] - ETA: 0s - loss: 0.3422 - accuracy: 0.93758/8 [==============================] - 0s 275us/step - loss: 0.4353 - accuracy: 0.8840
Model 66: [0.4352557957172394, 0.8840000033378601]
1/8 [==>...........................] - ETA: 0s - loss: 0.3367 - accuracy: 0.93758/8 [==============================] - 0s 291us/step - loss: 0.4353 - accuracy: 0.8800
Model 67: [0.4352627396583557, 0.8799999952316284]
1/8 [==>...........................] - ETA: 0s - loss: 0.3425 - accuracy: 0.93758/8 [==============================] - 0s 278us/step - loss: 0.4352 - accuracy: 0.8840
Model 68: [0.4352215826511383, 0.8840000033378601]
1/8 [==>...........................] - ETA: 0s - loss: 0.3397 - accuracy: 0.93758/8 [==============================] - 0s 277us/step - loss: 0.4352 - accuracy: 0.8800
Model 69: [0.43515703082084656, 0.8799999952316284]
1/8 [==>...........................] - ETA: 0s - loss: 0.3373 - accuracy: 0.93758/8 [==============================] - 0s 275us/step - loss: 0.4352 - accuracy: 0.8800
Model 70: [0.43524259328842163, 0.8799999952316284]
1/8 [==>...........................] - ETA: 0s - loss: 0.3363 - accuracy: 0.93758/8 [==============================] - 0s 278us/step - loss: 0.4364 - accuracy: 0.8840
Model 71: [0.4364232122898102, 0.8840000033378601]
1/8 [==>...........................] - ETA: 0s - loss: 0.3382 - accuracy: 0.93758/8 [==============================] - 0s 282us/step - loss: 0.4351 - accuracy: 0.8800
Model 72: [0.4350621700286865, 0.8799999952316284]
1/8 [==>...........................] - ETA: 0s - loss: 0.3376 - accuracy: 0.93758/8 [==============================] - 0s 270us/step - loss: 0.4351 - accuracy: 0.8760
Model 73: [0.43505460023880005, 0.8759999871253967]
1/8 [==>...........................] - ETA: 0s - loss: 0.3413 - accuracy: 0.90628/8 [==============================] - 0s 281us/step - loss: 0.4361 - accuracy: 0.8840
Model 74: [0.4360508322715759, 0.8840000033378601]
1/8 [==>...........................] - ETA: 0s - loss: 0.3419 - accuracy: 0.93758/8 [==============================] - 0s 272us/step - loss: 0.4357 - accuracy: 0.8880
Model 75: [0.4356975257396698, 0.8880000114440918]
1/8 [==>...........................] - ETA: 0s - loss: 0.3389 - accuracy: 0.93758/8 [==============================] - 0s 287us/step - loss: 0.4357 - accuracy: 0.8880
Model 76: [0.43572932481765747, 0.8880000114440918]
1/8 [==>...........................] - ETA: 0s - loss: 0.3358 - accuracy: 0.93758/8 [==============================] - 0s 279us/step - loss: 0.4352 - accuracy: 0.8760
Model 77: [0.4352319538593292, 0.8759999871253967]
1/8 [==>...........................] - ETA: 0s - loss: 0.3396 - accuracy: 0.93758/8 [==============================] - 0s 277us/step - loss: 0.4353 - accuracy: 0.8880
Model 78: [0.43530115485191345, 0.8880000114440918]
1/8 [==>...........................] - ETA: 0s - loss: 0.3395 - accuracy: 0.93758/8 [==============================] - 0s 273us/step - loss: 0.4351 - accuracy: 0.8800
Model 79: [0.43506184220314026, 0.8799999952316284]
1/8 [==>...........................] - ETA: 0s - loss: 0.3415 - accuracy: 0.93758/8 [==============================] - 0s 286us/step - loss: 0.4351 - accuracy: 0.8840
Model 80: [0.43506914377212524, 0.8840000033378601]
1/8 [==>...........................] - ETA: 0s - loss: 0.3370 - accuracy: 0.93758/8 [==============================] - 0s 280us/step - loss: 0.4352 - accuracy: 0.8800
Model 81: [0.43520107865333557, 0.8799999952316284]
1/8 [==>...........................] - ETA: 0s - loss: 0.3392 - accuracy: 0.93758/8 [==============================] - 0s 267us/step - loss: 0.4350 - accuracy: 0.8760
Model 82: [0.43502917885780334, 0.8759999871253967]
1/8 [==>...........................] - ETA: 0s - loss: 0.3411 - accuracy: 0.93758/8 [==============================] - 0s 276us/step - loss: 0.4351 - accuracy: 0.8840
Model 83: [0.43512415885925293, 0.8840000033378601]
1/8 [==>...........................] - ETA: 0s - loss: 0.3408 - accuracy: 0.93758/8 [==============================] - 0s 289us/step - loss: 0.4354 - accuracy: 0.8760
Model 84: [0.43538519740104675, 0.8759999871253967]
1/8 [==>...........................] - ETA: 0s - loss: 0.3381 - accuracy: 0.93758/8 [==============================] - 0s 269us/step - loss: 0.4354 - accuracy: 0.8800
Model 85: [0.435396283864975, 0.8799999952316284]
1/8 [==>...........................] - ETA: 0s - loss: 0.3397 - accuracy: 0.93758/8 [==============================] - 0s 275us/step - loss: 0.4354 - accuracy: 0.8840
Model 86: [0.43539220094680786, 0.8840000033378601]
1/8 [==>...........................] - ETA: 0s - loss: 0.3385 - accuracy: 0.93758/8 [==============================] - 0s 269us/step - loss: 0.4355 - accuracy: 0.8800
Model 87: [0.43552857637405396, 0.8799999952316284]
1/8 [==>...........................] - ETA: 0s - loss: 0.3396 - accuracy: 0.93758/8 [==============================] - 0s 279us/step - loss: 0.4351 - accuracy: 0.8840
Model 88: [0.4350586235523224, 0.8840000033378601]
1/8 [==>...........................] - ETA: 0s - loss: 0.3401 - accuracy: 0.93758/8 [==============================] - 0s 292us/step - loss: 0.4352 - accuracy: 0.8800
Model 89: [0.43517690896987915, 0.8799999952316284]
1/8 [==>...........................] - ETA: 0s - loss: 0.3396 - accuracy: 0.93758/8 [==============================] - 0s 279us/step - loss: 0.4354 - accuracy: 0.8840
Model 90: [0.4353688955307007, 0.8840000033378601]
1/8 [==>...........................] - ETA: 0s - loss: 0.3454 - accuracy: 0.90628/8 [==============================] - 0s 294us/step - loss: 0.4352 - accuracy: 0.8840
Model 91: [0.4351990818977356, 0.8840000033378601]
1/8 [==>...........................] - ETA: 0s - loss: 0.3398 - accuracy: 0.93758/8 [==============================] - 0s 292us/step - loss: 0.4354 - accuracy: 0.8880
Model 92: [0.4354066252708435, 0.8880000114440918]
1/8 [==>...........................] - ETA: 0s - loss: 0.3372 - accuracy: 0.93758/8 [==============================] - 0s 279us/step - loss: 0.4352 - accuracy: 0.8800
Model 93: [0.43518754839897156, 0.8799999952316284]
1/8 [==>...........................] - ETA: 0s - loss: 0.3408 - accuracy: 0.93758/8 [==============================] - 0s 282us/step - loss: 0.4353 - accuracy: 0.8840
Model 94: [0.435317724943161, 0.8840000033378601]
1/8 [==>...........................] - ETA: 0s - loss: 0.3407 - accuracy: 0.93758/8 [==============================] - 0s 280us/step - loss: 0.4356 - accuracy: 0.8760
Model 95: [0.435556024312973, 0.8759999871253967]
1/8 [==>...........................] - ETA: 0s - loss: 0.3410 - accuracy: 0.93758/8 [==============================] - 0s 283us/step - loss: 0.4352 - accuracy: 0.8880
Model 96: [0.43516460061073303, 0.8880000114440918]
1/8 [==>...........................] - ETA: 0s - loss: 0.3419 - accuracy: 0.93758/8 [==============================] - 0s 280us/step - loss: 0.4353 - accuracy: 0.8840
Model 97: [0.4352632164955139, 0.8840000033378601]
1/8 [==>...........................] - ETA: 0s - loss: 0.3371 - accuracy: 0.93758/8 [==============================] - 0s 292us/step - loss: 0.4350 - accuracy: 0.8800
Model 98: [0.4350479543209076, 0.8799999952316284]
1/8 [==>...........................] - ETA: 0s - loss: 0.3404 - accuracy: 0.93758/8 [==============================] - 0s 289us/step - loss: 0.4351 - accuracy: 0.8840
Model 99: [0.4351120591163635, 0.8840000033378601]
[SAVED TO all_outputs.txt] Gradient Descent Over!  Avg Score: 0.4453474673628807 Deviation: 0.037424919797672214 Best: 0.43497562408447266 Worst: 0.6391984820365906
[SAVED TO all_outputs.txt] Avg Accuracy: 0.8724799996614456 Deviation: 0.04358084138235812 Best: 0.6079999804496765 Worst: 0.8920000195503235
[SAVED TO all_outputs.txt] Saved Figure as "[7]sgd_gradient_descent1_pop30_time1000_avg100.pdf"
[SAVED TO all_outputs.txt] Saved Figure as "[8]sgd_test_result1.pdf"
[SAVED TO all_outputs.txt] Raw kwargs: {'total_a': 3.4, 'a1_percent': 0.5, 'epsilon': -0.21, 'population_size': 30, 'time_steps': 1000, 'a3': 0.0}
[SAVED TO all_outputs.txt] ARGS:  {'w': 0.5021822170828449, 'a1': 1.7, 'a2': 1.7, 'a3': 0.0, 'population_size': 30, 'time_steps': 1000, 'search_range': 1000, 'constrainer': <function run_script.<locals>.<lambda> at 0x7f223eca1160>}
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_2 (Dense)              (250, 8)                  40        
_________________________________________________________________
re_lu_1 (ReLU)               (250, 8)                  0         
_________________________________________________________________
dense_3 (Dense)              (250, 1)                  9         
=================================================================
Total params: 49
Trainable params: 49
Non-trainable params: 0
_________________________________________________________________
[SAVED TO all_outputs.txt] PSO 1 Training for 1000 Epochs with Population 30
init
Time:     49,  Best Fitness:       0.595392
Best Pos: [-9.36626972e+01 -3.16527591e+01  1.30600436e+02 -5.53054127e+02
 -6.85612052e+02  1.90204021e+01 -5.10153838e+02  4.20440673e+02
 -5.02662718e+02 -2.31741859e+02  1.76383748e+02  5.07095302e+02
 -5.26473967e+02  7.65115848e+02 -1.50455707e+02 -8.47347170e+01
  3.39360989e-01  5.15291390e+02 -5.46895090e+02  1.19907398e+02
 -1.48242725e+01  2.01242132e+02 -2.69570605e+02 -5.28761597e+01
 -3.61681384e+02  6.28138035e+02 -3.60797507e+02 -1.71652526e+02
  3.99636933e+02  1.33275042e+02 -4.11721704e+02 -2.07421834e+02
 -3.29922414e+02 -1.02452016e+02  2.03139591e+03  4.73887602e+02
  8.39951217e+03 -3.54506173e+03  1.94456599e+03 -8.71971054e+02
 -2.35698053e+02  1.87722687e+02 -2.47636869e+02 -3.53381642e+02
 -7.18310417e+01 -1.95358123e+03  4.71327941e+02 -5.71866567e+01
  1.82508626e+02]

Time:     99,  Best Fitness:       0.562035
Best Pos: [-9.41509652e+01 -3.18669637e+01  1.30911559e+02 -5.54073892e+02
 -6.84590786e+02  1.99061149e+01 -5.10303489e+02  4.26129585e+02
 -5.00040612e+02 -2.29471074e+02  1.74830010e+02  5.06379229e+02
 -5.26050143e+02  7.65288881e+02 -1.50988004e+02 -8.60593240e+01
  1.40395555e-01  5.16003290e+02 -5.46004753e+02  2.34707761e+01
 -1.96821370e+01  2.00472940e+02 -3.32964828e+02 -5.16690435e+01
 -3.61222520e+02  6.28314995e+02 -3.16462574e+02 -1.69533262e+02
  3.98317801e+02  1.36365599e+02 -4.13324614e+02 -2.09364081e+02
 -3.33239423e+02 -1.00086970e+02  2.03187776e+03  4.74853547e+02
  2.10485992e+04 -3.54308145e+03  2.46069589e+03 -8.73408414e+02
 -2.35108913e+02  3.64988559e+02 -2.47864781e+02 -3.54541994e+02
 -9.70888133e+01 -1.96127413e+03  1.13126633e+03 -5.81150764e+01
  1.83528209e+02]

Time:    149,  Best Fitness:       0.546909
Best Pos: [-9.26763748e+01 -3.07427827e+01  1.31179401e+02 -5.55620712e+02
 -6.84628252e+02  2.01768668e+01 -5.09914129e+02  4.24923547e+02
 -4.91977956e+02 -2.28532969e+02  1.75512111e+02 -7.28827322e+01
 -5.26129529e+02  7.66662235e+02 -1.51772573e+02 -8.66498477e+01
  2.00180507e-01  5.16363410e+02 -5.45553832e+02  1.05490808e+02
 -1.94649106e+01  2.16066323e+02 -3.33507890e+02 -5.02822698e+01
 -3.60477611e+02  6.27922176e+02 -3.17565813e+02 -1.69326532e+02
  3.98519715e+02  1.36957714e+02 -4.44901205e+02 -2.10237509e+02
 -3.34856290e+02 -9.52422662e+01  2.03188325e+03  4.75719266e+02
  2.10372819e+04 -3.54243710e+03  2.46072193e+03 -8.74251099e+02
 -2.33946114e+02  4.92921370e+02 -2.47464680e+02 -3.56097662e+02
 -1.29433440e+02 -1.96183517e+03  1.41965988e+03 -5.86132627e+01
  1.84612858e+02]

Time:    199,  Best Fitness:       0.531763
Best Pos: [-9.28079586e+01  1.39611495e+02  1.27892779e+02 -5.55594409e+02
 -6.84832823e+02  7.01508102e+01 -5.09302139e+02  4.24337342e+02
 -4.93201302e+02  4.99596347e+01  3.86335349e+02 -7.29429135e+01
 -5.27369364e+02  7.68831310e+02 -1.51956254e+02 -8.37581152e+01
  1.04270655e+00  5.16953751e+02 -5.44369780e+02  1.05177815e+02
 -1.85979047e+00  2.35786011e+02 -3.23766217e+02 -4.91848232e+01
 -3.60113722e+02  6.27895623e+02 -3.19129131e+02 -1.76717988e+02
  3.99147719e+02  1.65673374e+02 -4.45812413e+02 -2.11480407e+02
 -3.36436356e+02  7.03334027e+01  2.03177331e+03  4.75438805e+02
  2.10384633e+04 -3.54122418e+03  2.46039135e+03 -8.75441702e+02
 -2.32128314e+02  5.44438784e+02 -2.47790611e+02 -3.57231218e+02
 -1.34809738e+02 -1.96202724e+03  1.41849763e+03 -5.73912990e+01
  1.86138943e+02]

Time:    249,  Best Fitness:       0.519765
Best Pos: [-9.34121334e+01  1.40862734e+02  1.27953631e+02 -5.56370235e+02
 -6.84489369e+02  7.06881684e+01 -5.09288319e+02  4.24448613e+02
 -4.94256533e+02  3.00323469e+02  3.86599502e+02 -7.46270812e+01
 -5.27402059e+02  7.69980230e+02 -2.90801699e+02 -8.45955724e+01
  9.77959556e-01  4.88129448e+02 -5.42148220e+02  1.04335738e+02
 -8.59204223e-01  2.34691800e+02 -3.24649391e+02 -4.75614284e+01
 -3.60617482e+02  6.28676860e+02 -4.80373761e+02 -1.76582409e+02
  3.97983974e+02  1.91530634e+02 -5.11309072e+02 -2.12273482e+02
 -3.39193692e+02  1.07074239e+02  2.03167254e+03  4.74225038e+02
  2.10392139e+04 -3.54057089e+03  2.46198818e+03 -8.75932134e+02
 -2.30780546e+02  5.49052795e+02 -5.25899130e+02 -3.57948942e+02
 -1.22415811e+02 -1.96401522e+03  1.41928729e+03 -5.72532217e+01
  1.88126502e+02]

Time:    299,  Best Fitness:       0.492359
Best Pos: [-9.30994503e+01  1.40673445e+02 -3.79235496e+02 -5.56404590e+02
 -6.83552569e+02  6.93890596e+01 -4.93631264e+02  4.24643710e+02
 -4.94986495e+02  3.01360091e+02  3.88769507e+02 -7.62957719e+01
 -5.28601975e+02  7.70005337e+02 -2.89566018e+02 -8.43966031e+01
 -4.37595144e-01  4.89021480e+02 -5.38739186e+02  1.03457011e+02
 -1.17051263e-01  2.33032379e+02 -3.47615628e+02 -4.60298093e+01
 -3.61420961e+02  6.28356650e+02 -4.80834733e+02 -1.75826009e+02
  3.98469620e+02  1.89790449e+02 -5.13727445e+02 -2.09906724e+02
 -3.42676514e+02  1.09296949e+02  2.03260385e+03  4.76000142e+02
  2.10409520e+04 -3.54041075e+03  2.46242986e+03 -8.76733467e+02
 -2.30073752e+02  5.51114098e+02 -1.49615047e+03 -3.58818733e+02
 -1.29276403e+02 -1.96579789e+03  2.28199181e+03 -5.98923138e+01
  1.88938101e+02]

Time:    349,  Best Fitness:       0.471374
Best Pos: [-9.31020650e+01  1.41467404e+02 -6.73833085e+02 -5.59113964e+02
 -6.82686743e+02  6.92824172e+01 -4.95761531e+02  4.27898071e+02
 -4.96366976e+02  3.93023616e+02  3.91537213e+02 -7.59116449e+01
 -5.26920892e+02  7.32288829e+02 -2.87393384e+02 -8.42081004e+01
 -2.18242187e+00  4.89312611e+02 -7.23733409e+02  1.02055065e+02
 -1.49308043e-01  2.20887516e+02 -3.55968380e+02 -4.47668757e+01
 -3.59203956e+02  6.35840660e+02 -4.88621066e+02 -1.74903340e+02
  3.98495659e+02  1.92017323e+02 -5.13994233e+02 -2.10382737e+02
 -3.44648433e+02  1.12139783e+02  2.03355681e+03  4.76842138e+02
  2.10415890e+04 -3.53930906e+03  2.46293408e+03 -8.79040654e+02
 -2.29363611e+02  6.20768743e+02 -1.57027200e+03 -4.68100178e+02
 -1.36055204e+02 -2.61715936e+03  2.30759868e+03 -6.06375616e+01
  1.91810573e+02]

Time:    399,  Best Fitness:       0.443323
Best Pos: [-9.23775246e+01  1.41571994e+02 -1.50131081e+03 -5.60134988e+02
 -6.84748591e+02  7.40321342e+01 -5.85924120e+02  4.27139208e+02
 -4.94954421e+02  3.93678065e+02  3.91427509e+02 -7.60567964e+01
 -5.26476330e+02  7.34981416e+02 -2.86651762e+02 -8.43041168e+01
 -3.57824952e+00  4.90018952e+02 -1.36474945e+03  1.01429926e+02
  4.00109111e-01  2.18538800e+02 -3.72822407e+02 -4.24021224e+01
 -3.58086817e+02  6.33468579e+02 -6.22057349e+02 -1.73722054e+02
  3.98959861e+02  1.85121941e+02 -5.01971437e+02 -2.10832881e+02
 -3.46283863e+02  1.15814009e+02  2.03336150e+03  2.72785045e+02
  2.10425700e+04 -3.53816707e+03  2.46286625e+03 -8.81731427e+02
 -2.32420620e+02  6.51931119e+02 -1.56912645e+03 -4.68612546e+02
 -1.49514967e+02 -2.67483673e+03  2.30738917e+03 -6.13125626e+01
  1.92907893e+02]

Time:    449,  Best Fitness:       0.433136
Best Pos: [-9.23979819e+01  1.42727896e+02 -1.63725133e+03 -4.94941947e+02
 -6.85440709e+02  7.51881752e+01 -5.86346503e+02  4.26928293e+02
 -4.95796516e+02  3.93405154e+02  3.91095616e+02 -7.61843920e+01
 -5.27257921e+02  7.37169484e+02 -2.44756078e+02 -8.46597722e+01
 -5.01943463e+00  4.78323601e+02 -1.36402852e+03  1.00568553e+02
  1.78222113e+00  2.23175148e+02 -3.86631680e+02 -4.00284967e+01
 -3.57690354e+02  6.34553205e+02 -6.84703965e+02 -1.71423652e+02
  3.97435797e+02  1.90244515e+02 -5.12361332e+02 -2.11421358e+02
 -3.47848634e+02  1.19136416e+02  2.03417925e+03  2.73955372e+02
  2.10425924e+04 -3.53748078e+03  2.76063518e+03 -8.82769482e+02
 -2.31124468e+02  7.45946213e+02 -1.56872216e+03 -4.69543899e+02
 -1.77672375e+02 -2.67624464e+03  2.30737973e+03 -6.10814735e+01
  1.92708092e+02]

Time:    499,  Best Fitness:       0.425755
Best Pos: [-9.16817215e+01  1.41800172e+02 -1.63799697e+03 -4.95708672e+02
 -6.85771547e+02  8.93716505e+01 -6.58382223e+02  4.25981087e+02
 -4.95250516e+02  3.95036892e+02  3.90951932e+02 -7.65122204e+01
 -5.28969169e+02  7.39174315e+02 -2.44389529e+02 -8.40510638e+01
 -5.50595253e+00  4.79178823e+02 -1.36215771e+03  1.28789721e+02
  1.50813541e+00  2.23945179e+02 -4.27793077e+02 -3.82432999e+01
 -3.56818564e+02  6.54471544e+02 -6.76193472e+02 -1.64241327e+02
  3.97151136e+02  1.94664114e+02 -5.27133372e+02 -2.12890443e+02
 -3.49048822e+02  1.22196660e+02  2.03421445e+03  2.75721424e+02
  2.10427449e+04 -3.53693787e+03  2.94945549e+03 -8.83279890e+02
 -2.30570367e+02  7.92791890e+02 -1.63848989e+03 -4.69461764e+02
 -1.92531594e+02 -2.67831749e+03  2.30742871e+03 -6.18237173e+01
  1.93998369e+02]

Time:    549,  Best Fitness:       0.421591
Best Pos: [-9.14247606e+01  1.41491264e+02 -1.63844240e+03 -4.97024253e+02
 -6.85090009e+02  8.99778057e+01 -7.03860622e+02  4.26249271e+02
 -4.96996424e+02  3.94772111e+02  5.65616552e+02 -7.55458810e+01
 -5.29362394e+02  7.43335852e+02 -2.43859540e+02 -8.53025374e+01
 -5.17704827e+00  4.79404438e+02 -1.36151334e+03  1.28463754e+02
 -8.68797721e-01  2.28268622e+02 -4.48477035e+02 -3.70305651e+01
 -3.56074555e+02  6.56709799e+02 -6.76169647e+02 -1.45453925e+02
  3.95745540e+02  1.99702891e+02 -5.52392941e+02 -2.13167932e+02
 -3.53188140e+02  1.26618958e+02  2.03422050e+03  2.75687627e+02
  2.10422550e+04 -3.53621057e+03  3.02130718e+03 -8.83738971e+02
 -2.30103942e+02  8.14274447e+02 -1.63928261e+03 -4.69348857e+02
 -1.96186410e+02 -2.67936620e+03  2.30800414e+03 -6.26465681e+01
  1.92578919e+02]

Time:    599,  Best Fitness:       0.418278
Best Pos: [-9.21646750e+01  2.37613808e+02 -1.63935952e+03 -4.95414685e+02
 -2.52011518e+02  9.15685151e+01 -7.11487453e+02  4.25603307e+02
 -4.98831949e+02  3.95891902e+02  5.64655173e+02 -7.53392949e+01
 -5.29746360e+02  7.46967613e+02 -2.39184788e+02 -8.49217995e+01
 -5.89928435e+00  4.80331284e+02 -1.36049320e+03  1.27716022e+02
 -6.26307373e-02  2.28343177e+02 -4.61565889e+02 -3.19251694e+01
 -3.53305661e+02  6.84677492e+02 -6.83447887e+02 -1.42617832e+02
  3.97023678e+02  2.05263830e+02 -5.54553984e+02 -2.13467751e+02
 -3.55688690e+02  1.28764499e+02  2.03631802e+03  2.77177317e+02
  2.10435902e+04 -3.53465148e+03  3.13769464e+03 -8.84798510e+02
 -2.29626212e+02  8.44517844e+02 -1.63960149e+03 -4.70352916e+02
 -2.11025465e+02 -2.68023819e+03  2.30804687e+03 -6.41226576e+01
  1.91087045e+02]

Time:    649,  Best Fitness:       0.413561
Best Pos: [-9.24852157e+01  2.77620759e+02 -1.64015574e+03 -4.95427534e+02
 -9.06033103e+01  9.15307168e+01 -7.14911172e+02  4.26220043e+02
 -4.99189848e+02  4.07716144e+02  5.63628758e+02 -7.52979560e+01
 -5.31309220e+02  8.09344195e+02 -2.40230073e+02 -8.47475240e+01
 -5.67098120e+00  4.79320887e+02 -1.35918388e+03  1.27346166e+02
  1.05239505e+00  2.34851818e+02 -4.62800061e+02 -2.93293665e+01
 -3.52065542e+02  6.85671084e+02 -6.96392247e+02 -1.41287469e+02
  3.96584936e+02  2.13312135e+02 -5.84759318e+02 -2.13366795e+02
 -3.58831487e+02  1.26105686e+02  2.03788965e+03  2.77535681e+02
  2.10440927e+04 -3.78371987e+03  3.19847227e+03 -8.83863315e+02
 -2.28896244e+02  8.56815721e+02 -1.63999589e+03 -4.71750923e+02
 -2.15998451e+02 -2.68115032e+03  2.30762310e+03 -6.39016893e+01
  1.92782336e+02]

Time:    699,  Best Fitness:       0.398759
Best Pos: [-8.97300241e+01  2.79201099e+02 -1.63946424e+03 -4.95886312e+02
 -9.12627234e+01  9.11366339e+01 -7.14716743e+02  4.25402116e+02
 -5.00237816e+02  4.08290455e+02  5.62994482e+02 -7.55799408e+01
 -5.30616430e+02  1.29767480e+03 -2.39378901e+02 -8.41460981e+01
 -6.60472420e+00  4.79991023e+02 -1.35836969e+03  1.23699732e+02
  1.79117667e+00  3.32146725e+02 -4.63451143e+02 -2.80846087e+01
 -3.50828068e+02  6.91189090e+02 -6.95251930e+02 -1.39682013e+02
  3.97423307e+02  2.12633955e+02 -5.84419708e+02 -2.14026734e+02
 -3.59116842e+02  1.26853174e+02  2.03673689e+03  2.78632921e+02
  2.10458760e+04 -5.58712595e+03  3.20090657e+03 -8.84484929e+02
 -2.29338316e+02  8.60963694e+02 -1.64005397e+03 -4.72079310e+02
 -2.15672501e+02 -2.68226351e+03  2.30714429e+03 -6.42211829e+01
  1.94377949e+02]

Time:    749,  Best Fitness:       0.392617
Best Pos: [-8.94342938e+01  2.83848716e+02 -1.64035333e+03 -4.95724993e+02
 -9.06191088e+01  4.87792640e+01 -7.14541998e+02  4.25677085e+02
 -4.99400057e+02  4.09954071e+02  5.64629792e+02 -7.59437678e+01
 -5.29947510e+02  1.32399752e+03 -2.38838688e+02 -8.40170437e+01
 -6.29625848e+00  4.79382844e+02 -1.35698877e+03  1.23119695e+02
  3.48872496e+00  3.51034149e+02 -4.64998585e+02 -2.61172620e+01
 -3.52115633e+02  6.92387936e+02 -6.95651597e+02 -1.38611732e+02
  3.96969956e+02  2.44936548e+02 -5.85143631e+02 -2.14397645e+02
 -3.60269891e+02  1.28495522e+02  2.03837301e+03  2.79606241e+02
  2.10463801e+04 -5.93710320e+03  3.20072695e+03 -8.82192170e+02
 -2.28263757e+02  9.56212558e+02 -1.64061470e+03 -4.72315352e+02
 -2.39012547e+02 -2.68567061e+03  2.45687556e+03 -6.44514807e+01
  1.90915328e+02]

Time:    799,  Best Fitness:       0.388059
Best Pos: [-8.90447386e+01  2.85060152e+02 -1.64119907e+03 -4.97420978e+02
 -9.04091924e+01  6.18414159e+01 -7.15198866e+02  4.23528627e+02
 -4.98798027e+02  4.55118401e+02  5.64178159e+02 -7.64644146e+01
 -5.27652031e+02  1.32535333e+03 -2.39139621e+02 -8.31401857e+01
 -7.31579929e+00  4.64969534e+02 -1.35660259e+03  1.28607551e+02
  5.73995912e+00  3.55321937e+02 -4.65621134e+02 -2.38415248e+01
 -3.52030221e+02  6.82343008e+02 -6.95332764e+02 -1.38029358e+02
  3.97665471e+02  2.68224265e+02 -5.69458780e+02 -2.15781314e+02
 -3.64221810e+02  1.30844501e+02  2.04041736e+03  2.80565780e+02
  2.10461498e+04 -5.93450786e+03  3.20101791e+03 -8.82833906e+02
 -2.26579055e+02  1.02419725e+03 -1.79437811e+03 -4.78035862e+02
 -2.44580895e+02 -2.68595513e+03  2.53023615e+03 -6.38009851e+01
  1.90854471e+02]

Time:    849,  Best Fitness:       0.383221
Best Pos: [-8.88030180e+01  2.85967214e+02 -1.64260670e+03 -4.98328541e+02
 -8.90639549e+01  6.24623458e+01 -7.15994509e+02  4.23879338e+02
 -4.97882110e+02  4.89056437e+02  5.62908473e+02 -7.55147561e+01
 -5.26467670e+02  1.32831496e+03 -2.80124448e+02 -8.25800373e+01
 -6.82834576e+00  4.83687375e+02 -1.35576893e+03  1.29530926e+02
  6.44476021e+00  3.54255715e+02 -4.81178199e+02 -2.04654277e+01
 -3.51510129e+02  7.30903440e+02 -6.97943977e+02 -1.46912876e+02
  3.97466340e+02  2.67735494e+02 -6.15896784e+02 -2.15120607e+02
 -3.65416170e+02  1.34011442e+02  2.03778291e+03  2.81448954e+02
  2.10453959e+04 -5.93264119e+03  3.46238090e+03 -8.82915892e+02
 -2.23679579e+02  1.02540815e+03 -1.79518532e+03 -4.78011387e+02
 -2.68538020e+02 -2.68650783e+03  2.53125265e+03 -6.23438433e+01
  1.93670762e+02]

Time:    899,  Best Fitness:       0.379297
Best Pos: [-8.86607076e+01  2.87530937e+02 -1.65498636e+03 -4.99035903e+02
 -8.88488090e+01  8.57111630e+01 -7.16458981e+02  4.24435308e+02
 -4.98686013e+02  4.90358130e+02  5.63271535e+02 -7.71978664e+01
 -5.26756780e+02  1.32756147e+03 -2.82836281e+02 -8.15697149e+01
 -7.20975711e+00  5.03709278e+02 -1.35535198e+03  1.28800064e+02
  3.06833788e+00  3.61170518e+02 -4.89721123e+02 -1.92919020e+01
 -3.48874599e+02  7.54284335e+02 -6.97958393e+02 -1.41515704e+02
  3.97857884e+02  2.70871218e+02 -6.24827770e+02 -2.14529554e+02
 -3.66586507e+02  1.37536114e+02  2.04061284e+03  2.82468970e+02
  2.10461658e+04 -5.93191436e+03  3.53093139e+03 -8.84629126e+02
 -2.22217342e+02  1.02815724e+03 -2.07972170e+03 -5.15945191e+02
 -2.77568635e+02 -2.68732050e+03  2.67236318e+03 -6.32259329e+01
  1.93293502e+02]

Time:    949,  Best Fitness:       0.376668
Best Pos: [-8.83410802e+01  2.87553281e+02 -1.68794161e+03 -5.00938572e+02
 -8.99815080e+01  8.33930911e+01 -7.96416310e+02  4.24773334e+02
 -4.97126033e+02  4.91254263e+02  5.61209310e+02 -7.85778754e+01
 -5.27342045e+02  1.32890412e+03 -2.57510163e+02 -8.19434733e+01
 -6.82754054e+00  5.03956595e+02 -1.35340436e+03  1.28410604e+02
  3.60416760e+00  3.62010624e+02 -5.26704647e+02 -1.69040555e+01
 -3.45124495e+02  7.45629486e+02 -6.98264523e+02 -1.39790486e+02
  3.97329902e+02  2.72198322e+02 -6.35189917e+02 -2.16085313e+02
 -3.68354160e+02  1.40668546e+02  2.04230083e+03  2.83168718e+02
  2.10469998e+04 -5.93056902e+03  3.60355263e+03 -8.85092952e+02
 -2.20953935e+02  1.06770621e+03 -2.10350744e+03 -5.41553347e+02
 -2.84755691e+02 -2.70115118e+03  2.69652318e+03 -6.40444658e+01
  1.93005473e+02]

Time:    999,  Best Fitness:       0.374872
Best Pos: [-8.81637907e+01  2.89601389e+02 -1.68867711e+03 -5.03384667e+02
 -9.13947609e+01  8.30838169e+01 -7.96310018e+02  4.23753309e+02
 -4.97606617e+02  5.12931671e+02  5.60916840e+02 -7.83267492e+01
 -5.29173160e+02  1.33072786e+03 -2.57416773e+02 -8.12531284e+01
 -5.92935304e+00  5.11607241e+02 -1.35153542e+03  1.26846360e+02
  2.69262296e+00  3.62318622e+02 -5.28501711e+02 -1.54135094e+01
 -3.43744010e+02  7.43784346e+02 -6.99407193e+02 -1.40113139e+02
  3.00433100e+02  2.80345899e+02 -6.53357960e+02 -2.17712497e+02
 -3.70875022e+02  1.44315553e+02  2.07271423e+03  2.84822309e+02
  2.10475222e+04 -5.93036258e+03  3.72700841e+03 -8.85059082e+02
 -2.17309887e+02  1.08059899e+03 -2.10685128e+03 -5.43030483e+02
 -2.98222972e+02 -2.70193731e+03  2.69576999e+03 -6.44447786e+01
  1.93490327e+02]

1/8 [==>...........................] - ETA: 0s - loss: 0.4733 - accuracy: 0.90628/8 [==============================] - 0s 326us/step - loss: 0.4273 - accuracy: 0.9080
[SAVED TO all_outputs.txt] PSO Training Over!  Score: [0.4272737205028534, 0.9079999923706055]
[SAVED TO all_outputs.txt] Saved Figure as "[9]pso1.pdf"
[SAVED TO all_outputs.txt] ARGS:  {'population_size': 30, 'time_steps': 100, 'mutation_rate': 0.1, 'crossover_rate': 0.8, 'train_epochs': 200, 'test_epochs': 1000, 'batch': 20}
[SAVED TO all_outputs.txt] GA 1 Training for 100 Generations with Population 30
1/100: Best Fitness 0.5555696487426758
6/100: Best Fitness 0.5308319926261902
11/100: Best Fitness 0.5308319926261902
16/100: Best Fitness 0.506860613822937
21/100: Best Fitness 0.5044264197349548
26/100: Best Fitness 0.5044264197349548
31/100: Best Fitness 0.5020272731781006
36/100: Best Fitness 0.5020272731781006
41/100: Best Fitness 0.5020272731781006
46/100: Best Fitness 0.5020272731781006
51/100: Best Fitness 0.5020272731781006
56/100: Best Fitness 0.4513826370239258
61/100: Best Fitness 0.4513826370239258
66/100: Best Fitness 0.4513826370239258
71/100: Best Fitness 0.4513826370239258
76/100: Best Fitness 0.4513826370239258
81/100: Best Fitness 0.4513826370239258
86/100: Best Fitness 0.4513826370239258
91/100: Best Fitness 0.4513826370239258
96/100: Best Fitness 0.4513826370239258
100/100: Best Fitness 0.4513826370239258
Model: "sequential_3033"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_10735 (Dense)          (None, 11)                55        
_________________________________________________________________
re_lu_7702 (ReLU)            (None, 11)                0         
_________________________________________________________________
dense_10736 (Dense)          (None, 7)                 84        
_________________________________________________________________
re_lu_7703 (ReLU)            (None, 7)                 0         
_________________________________________________________________
dense_10737 (Dense)          (None, 5)                 40        
_________________________________________________________________
re_lu_7704 (ReLU)            (None, 5)                 0         
_________________________________________________________________
dense_10738 (Dense)          (None, 9)                 54        
_________________________________________________________________
re_lu_7705 (ReLU)            (None, 9)                 0         
_________________________________________________________________
dense_10739 (Dense)          (None, 7)                 70        
_________________________________________________________________
re_lu_7706 (ReLU)            (None, 7)                 0         
_________________________________________________________________
dense_10740 (Dense)          (None, 1)                 8         
=================================================================
Total params: 311
Trainable params: 311
Non-trainable params: 0
_________________________________________________________________
1/8 [==>...........................] - ETA: 0s - loss: 0.4515 - accuracy: 0.87508/8 [==============================] - 0s 478us/step - loss: 0.3461 - accuracy: 0.9080
[SAVED TO all_outputs.txt] GA Best (with genotype 1 101 Uniform,1 011 HeNormal,1 010 Normal,1 100 Uniform,1 011 Uniform):  [0.34613096714019775, 0.9079999923706055]
[SAVED TO all_outputs.txt] Saved Figure as "[10]plot_of_ga_accuracies_over_time.pdf"
[SAVED TO all_outputs.txt] Saved Figure as "[11]ga1.pdf"
[SAVED TO all_outputs.txt] ARGS:  {'population_size': 30, 'time_steps': 100, 'mutation_rate': 0.5, 'crossover_rate': 0.1, 'flip_chance': 0.5, 'whither_rate': 0.8, 'growth_rate': 0.1, 'train_epochs': 200, 'test_epochs': 1000, 'batch': 20}
[SAVED TO all_outputs.txt] GP 1 Training for 100 Generations with Population 30
1/100: Best Fitness 0.6404196619987488
6/100: Best Fitness 0.5973465442657471
11/100: Best Fitness 0.5973465442657471
16/100: Best Fitness 0.5973465442657471
21/100: Best Fitness 0.5973465442657471
26/100: Best Fitness 0.5962122678756714
31/100: Best Fitness 0.5962122678756714
36/100: Best Fitness 0.5962122678756714
41/100: Best Fitness 0.5962122678756714
46/100: Best Fitness 0.5962122678756714
51/100: Best Fitness 0.5962122678756714
56/100: Best Fitness 0.5962122678756714
61/100: Best Fitness 0.5962122678756714
66/100: Best Fitness 0.5962122678756714
71/100: Best Fitness 0.5962122678756714
76/100: Best Fitness 0.5962122678756714
81/100: Best Fitness 0.5962122678756714
86/100: Best Fitness 0.5962122678756714
91/100: Best Fitness 0.5962122678756714
96/100: Best Fitness 0.5962122678756714
100/100: Best Fitness 0.5962122678756714
[SAVED TO all_outputs.txt] Saved Figure as "[12]depthhistory1.pdf"
Model: "functional_6063"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_3032 (InputLayer)         [(None, 500, 4)]     0                                            
__________________________________________________________________________________________________
dense_18523 (Dense)             (None, 500, 4)       20          input_3032[0][0]                 
__________________________________________________________________________________________________
dense_18524 (Dense)             (None, 500, 4)       20          input_3032[0][0]                 
__________________________________________________________________________________________________
concatenate_860 (Concatenate)   (None, 500, 8)       0           dense_18523[0][0]                
                                                                 dense_18524[0][0]                
__________________________________________________________________________________________________
dense_18525 (Dense)             (None, 500, 3)       27          concatenate_860[0][0]            
__________________________________________________________________________________________________
activation_587 (Activation)     (None, 500, 3)       0           dense_18525[0][0]                
__________________________________________________________________________________________________
dense_18526 (Dense)             (None, 500, 1)       4           activation_587[0][0]             
==================================================================================================
Total params: 71
Trainable params: 71
Non-trainable params: 0
__________________________________________________________________________________________________
1/8 [==>...........................] - ETA: 0s - loss: 0.6099 - accuracy: 0.71888/8 [==============================] - 0s 452us/step - loss: 0.5947 - accuracy: 0.7200
[SAVED TO all_outputs.txt] GP Best (binary_crossentropy, accuracy):  [0.5946568250656128, 0.7200000286102295] 
 With key: Swish[3, Uniform]: (Input,Input)
[SAVED TO all_outputs.txt] Saved Figure as "[13]plot_of_gp_accuracies_over_time.pdf"
[SAVED TO all_outputs.txt] Saved Figure as "[14]gp1.pdf"
