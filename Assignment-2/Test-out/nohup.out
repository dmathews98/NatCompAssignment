2020-11-14 13:46:55.565026: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-11-14 13:46:55.570501: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2345480000 Hz
2020-11-14 13:46:55.572235: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56251eef89f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-11-14 13:46:55.572252: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
full data
[SAVED TO all_outputs.txt] Saved Figure as "[1]full_data_plot.png"
train data
[SAVED TO all_outputs.txt] Saved Figure as "[2]train_data_plot.png"
test data
[SAVED TO all_outputs.txt] Saved Figure as "[3]test_data_plot.png"
[SAVED TO all_outputs.txt] ARGS:  {'population_size': 15, 'time_steps': 500, 'averaging': 100}
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense (Dense)                (500, 8)                  56        
_________________________________________________________________
re_lu (ReLU)                 (500, 8)                  0         
_________________________________________________________________
dense_1 (Dense)              (500, 1)                  9         
=================================================================
Total params: 65
Trainable params: 65
Non-trainable params: 0
_________________________________________________________________
[SAVED TO all_outputs.txt] Gradient Descent 1 Training for 500 Epochs with 15 per Batch
1/8 [==>...........................] - ETA: 0s - loss: 0.4832 - accuracy: 0.90628/8 [==============================] - 0s 374us/step - loss: 0.5095 - accuracy: 0.8280
Model 0: [0.5094572305679321, 0.828000009059906]
1/8 [==>...........................] - ETA: 0s - loss: 0.3524 - accuracy: 0.96888/8 [==============================] - 0s 370us/step - loss: 0.3740 - accuracy: 0.9400
Model 1: [0.37403473258018494, 0.9399999976158142]
1/8 [==>...........................] - ETA: 0s - loss: 0.2993 - accuracy: 1.00008/8 [==============================] - 0s 319us/step - loss: 0.3186 - accuracy: 0.9480
Model 2: [0.31856662034988403, 0.9480000138282776]
1/8 [==>...........................] - ETA: 0s - loss: 0.2864 - accuracy: 0.96888/8 [==============================] - 0s 345us/step - loss: 0.3041 - accuracy: 0.9520
Model 3: [0.3040960133075714, 0.9520000219345093]
1/8 [==>...........................] - ETA: 0s - loss: 0.2713 - accuracy: 1.00008/8 [==============================] - 0s 346us/step - loss: 0.2901 - accuracy: 0.9640
Model 4: [0.2900555729866028, 0.9639999866485596]
1/8 [==>...........................] - ETA: 0s - loss: 0.2672 - accuracy: 1.00008/8 [==============================] - 0s 393us/step - loss: 0.2775 - accuracy: 0.9800
Model 5: [0.2774653434753418, 0.9800000190734863]
1/8 [==>...........................] - ETA: 0s - loss: 0.2638 - accuracy: 1.00008/8 [==============================] - 0s 379us/step - loss: 0.2724 - accuracy: 0.9840
Model 6: [0.27239367365837097, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.2585 - accuracy: 1.00008/8 [==============================] - 0s 352us/step - loss: 0.2663 - accuracy: 0.9880
Model 7: [0.26633933186531067, 0.9879999756813049]
1/8 [==>...........................] - ETA: 0s - loss: 0.2536 - accuracy: 1.00008/8 [==============================] - 0s 373us/step - loss: 0.2643 - accuracy: 0.9880
Model 8: [0.26428094506263733, 0.9879999756813049]
1/8 [==>...........................] - ETA: 0s - loss: 0.2557 - accuracy: 1.00008/8 [==============================] - 0s 397us/step - loss: 0.2628 - accuracy: 0.9880
Model 9: [0.2627703845500946, 0.9879999756813049]
1/8 [==>...........................] - ETA: 0s - loss: 0.2511 - accuracy: 1.00008/8 [==============================] - 0s 325us/step - loss: 0.2614 - accuracy: 0.9840
Model 10: [0.26142433285713196, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.2363 - accuracy: 1.00008/8 [==============================] - 0s 329us/step - loss: 0.2488 - accuracy: 0.9840
Model 11: [0.24878014624118805, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.2208 - accuracy: 1.00008/8 [==============================] - 0s 330us/step - loss: 0.2410 - accuracy: 0.9840
Model 12: [0.24097612500190735, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.2152 - accuracy: 1.00008/8 [==============================] - 0s 311us/step - loss: 0.2368 - accuracy: 0.9840
Model 13: [0.2367817461490631, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.2105 - accuracy: 1.00008/8 [==============================] - 0s 351us/step - loss: 0.2334 - accuracy: 0.9840
Model 14: [0.23338140547275543, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.2079 - accuracy: 1.00008/8 [==============================] - 0s 317us/step - loss: 0.2310 - accuracy: 0.9840
Model 15: [0.23099537193775177, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.2039 - accuracy: 1.00008/8 [==============================] - 0s 321us/step - loss: 0.2300 - accuracy: 0.9840
Model 16: [0.22995220124721527, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.2026 - accuracy: 1.00008/8 [==============================] - 0s 328us/step - loss: 0.2278 - accuracy: 0.9840
Model 17: [0.2277926802635193, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.2005 - accuracy: 1.00008/8 [==============================] - 0s 323us/step - loss: 0.2260 - accuracy: 0.9840
Model 18: [0.22602060437202454, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1990 - accuracy: 1.00008/8 [==============================] - 0s 374us/step - loss: 0.2241 - accuracy: 0.9840
Model 19: [0.22414115071296692, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1937 - accuracy: 1.00008/8 [==============================] - 0s 310us/step - loss: 0.2224 - accuracy: 0.9840
Model 20: [0.22242575883865356, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1946 - accuracy: 1.00008/8 [==============================] - 0s 317us/step - loss: 0.2214 - accuracy: 0.9840
Model 21: [0.22143271565437317, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1943 - accuracy: 1.00008/8 [==============================] - 0s 338us/step - loss: 0.2207 - accuracy: 0.9840
Model 22: [0.2206791639328003, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1907 - accuracy: 1.00008/8 [==============================] - 0s 295us/step - loss: 0.2197 - accuracy: 0.9840
Model 23: [0.21969366073608398, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1922 - accuracy: 1.00008/8 [==============================] - 0s 296us/step - loss: 0.2196 - accuracy: 0.9840
Model 24: [0.2196113020181656, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1908 - accuracy: 1.00008/8 [==============================] - 0s 306us/step - loss: 0.2187 - accuracy: 0.9840
Model 25: [0.21872735023498535, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1903 - accuracy: 1.00008/8 [==============================] - 0s 321us/step - loss: 0.2180 - accuracy: 0.9840
Model 26: [0.21801552176475525, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1911 - accuracy: 1.00008/8 [==============================] - 0s 334us/step - loss: 0.2178 - accuracy: 0.9840
Model 27: [0.21781696379184723, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1900 - accuracy: 1.00008/8 [==============================] - 0s 301us/step - loss: 0.2134 - accuracy: 0.9800
Model 28: [0.21342943608760834, 0.9800000190734863]
1/8 [==>...........................] - ETA: 0s - loss: 0.1882 - accuracy: 1.00008/8 [==============================] - 0s 305us/step - loss: 0.2119 - accuracy: 0.9840
Model 29: [0.211945042014122, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1856 - accuracy: 1.00008/8 [==============================] - 0s 350us/step - loss: 0.2107 - accuracy: 0.9840
Model 30: [0.2106592357158661, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1855 - accuracy: 1.00008/8 [==============================] - 0s 298us/step - loss: 0.2102 - accuracy: 0.9840
Model 31: [0.21023167669773102, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1848 - accuracy: 1.00008/8 [==============================] - 0s 306us/step - loss: 0.2099 - accuracy: 0.9840
Model 32: [0.20994623005390167, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1853 - accuracy: 1.00008/8 [==============================] - 0s 304us/step - loss: 0.2096 - accuracy: 0.9840
Model 33: [0.20958781242370605, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1848 - accuracy: 1.00008/8 [==============================] - 0s 302us/step - loss: 0.2094 - accuracy: 0.9840
Model 34: [0.20938879251480103, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1849 - accuracy: 1.00008/8 [==============================] - 0s 330us/step - loss: 0.2099 - accuracy: 0.9840
Model 35: [0.20994876325130463, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1853 - accuracy: 1.00008/8 [==============================] - 0s 328us/step - loss: 0.2090 - accuracy: 0.9840
Model 36: [0.20897763967514038, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1846 - accuracy: 1.00008/8 [==============================] - 0s 299us/step - loss: 0.2088 - accuracy: 0.9840
Model 37: [0.20876376330852509, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1845 - accuracy: 1.00008/8 [==============================] - 0s 302us/step - loss: 0.2086 - accuracy: 0.9840
Model 38: [0.20864157378673553, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1840 - accuracy: 1.00008/8 [==============================] - 0s 323us/step - loss: 0.2085 - accuracy: 0.9840
Model 39: [0.20854179561138153, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1836 - accuracy: 1.00008/8 [==============================] - 0s 306us/step - loss: 0.2084 - accuracy: 0.9840
Model 40: [0.20837463438510895, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1842 - accuracy: 1.00008/8 [==============================] - 0s 329us/step - loss: 0.2085 - accuracy: 0.9840
Model 41: [0.20850756764411926, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1837 - accuracy: 1.00008/8 [==============================] - 0s 306us/step - loss: 0.2082 - accuracy: 0.9840
Model 42: [0.20823350548744202, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1824 - accuracy: 1.00008/8 [==============================] - 0s 307us/step - loss: 0.2080 - accuracy: 0.9840
Model 43: [0.2079617977142334, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1823 - accuracy: 1.00008/8 [==============================] - 0s 342us/step - loss: 0.2077 - accuracy: 0.9840
Model 44: [0.20765359699726105, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1823 - accuracy: 1.00008/8 [==============================] - 0s 303us/step - loss: 0.2074 - accuracy: 0.9840
Model 45: [0.2073826789855957, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1803 - accuracy: 1.00008/8 [==============================] - 0s 303us/step - loss: 0.2074 - accuracy: 0.9800
Model 46: [0.20738376677036285, 0.9800000190734863]
1/8 [==>...........................] - ETA: 0s - loss: 0.1817 - accuracy: 1.00008/8 [==============================] - 0s 318us/step - loss: 0.2076 - accuracy: 0.9840
Model 47: [0.20760701596736908, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1820 - accuracy: 1.00008/8 [==============================] - 0s 301us/step - loss: 0.2070 - accuracy: 0.9840
Model 48: [0.2070479393005371, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1815 - accuracy: 1.00008/8 [==============================] - 0s 327us/step - loss: 0.2070 - accuracy: 0.9840
Model 49: [0.2069520801305771, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1818 - accuracy: 1.00008/8 [==============================] - 0s 308us/step - loss: 0.2069 - accuracy: 0.9840
Model 50: [0.20688258111476898, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1807 - accuracy: 1.00008/8 [==============================] - 0s 295us/step - loss: 0.2068 - accuracy: 0.9840
Model 51: [0.20683151483535767, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1822 - accuracy: 1.00008/8 [==============================] - 0s 293us/step - loss: 0.2068 - accuracy: 0.9840
Model 52: [0.20679688453674316, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1811 - accuracy: 1.00008/8 [==============================] - 0s 302us/step - loss: 0.2066 - accuracy: 0.9840
Model 53: [0.2065751552581787, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1813 - accuracy: 1.00008/8 [==============================] - 0s 301us/step - loss: 0.2066 - accuracy: 0.9840
Model 54: [0.2066325694322586, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1821 - accuracy: 1.00008/8 [==============================] - 0s 335us/step - loss: 0.2069 - accuracy: 0.9840
Model 55: [0.20694252848625183, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1805 - accuracy: 1.00008/8 [==============================] - 0s 319us/step - loss: 0.2064 - accuracy: 0.9840
Model 56: [0.2064211666584015, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1812 - accuracy: 1.00008/8 [==============================] - 0s 301us/step - loss: 0.2064 - accuracy: 0.9840
Model 57: [0.20639772713184357, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1809 - accuracy: 1.00008/8 [==============================] - 0s 301us/step - loss: 0.2066 - accuracy: 0.9840
Model 58: [0.20659039914608002, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1809 - accuracy: 1.00008/8 [==============================] - 0s 304us/step - loss: 0.2066 - accuracy: 0.9840
Model 59: [0.20656684041023254, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1813 - accuracy: 1.00008/8 [==============================] - 0s 291us/step - loss: 0.2062 - accuracy: 0.9840
Model 60: [0.20623095333576202, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1809 - accuracy: 1.00008/8 [==============================] - 0s 299us/step - loss: 0.2062 - accuracy: 0.9840
Model 61: [0.20622803270816803, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1807 - accuracy: 1.00008/8 [==============================] - 0s 295us/step - loss: 0.2062 - accuracy: 0.9840
Model 62: [0.2062491774559021, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1805 - accuracy: 1.00008/8 [==============================] - 0s 331us/step - loss: 0.2061 - accuracy: 0.9840
Model 63: [0.206136092543602, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1809 - accuracy: 1.00008/8 [==============================] - 0s 293us/step - loss: 0.2061 - accuracy: 0.9840
Model 64: [0.20605625212192535, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1813 - accuracy: 1.00008/8 [==============================] - 0s 317us/step - loss: 0.2067 - accuracy: 0.9840
Model 65: [0.2067122906446457, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1810 - accuracy: 1.00008/8 [==============================] - 0s 300us/step - loss: 0.2060 - accuracy: 0.9840
Model 66: [0.20598681271076202, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1807 - accuracy: 1.00008/8 [==============================] - 0s 309us/step - loss: 0.2060 - accuracy: 0.9840
Model 67: [0.20599284768104553, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1800 - accuracy: 1.00008/8 [==============================] - 0s 296us/step - loss: 0.2062 - accuracy: 0.9840
Model 68: [0.2061956226825714, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1797 - accuracy: 1.00008/8 [==============================] - 0s 297us/step - loss: 0.2060 - accuracy: 0.9840
Model 69: [0.20596253871917725, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1809 - accuracy: 1.00008/8 [==============================] - 0s 304us/step - loss: 0.2060 - accuracy: 0.9840
Model 70: [0.20597754418849945, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1798 - accuracy: 1.00008/8 [==============================] - 0s 302us/step - loss: 0.2058 - accuracy: 0.9840
Model 71: [0.2058497965335846, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1804 - accuracy: 1.00008/8 [==============================] - 0s 320us/step - loss: 0.2058 - accuracy: 0.9840
Model 72: [0.2058417648077011, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1811 - accuracy: 1.00008/8 [==============================] - 0s 303us/step - loss: 0.2058 - accuracy: 0.9840
Model 73: [0.2058154046535492, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1803 - accuracy: 1.00008/8 [==============================] - 0s 294us/step - loss: 0.2058 - accuracy: 0.9840
Model 74: [0.20584237575531006, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1806 - accuracy: 1.00008/8 [==============================] - 0s 299us/step - loss: 0.2060 - accuracy: 0.9840
Model 75: [0.20597675442695618, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1805 - accuracy: 1.00008/8 [==============================] - 0s 302us/step - loss: 0.2058 - accuracy: 0.9840
Model 76: [0.20578165352344513, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1811 - accuracy: 1.00008/8 [==============================] - 0s 344us/step - loss: 0.2059 - accuracy: 0.9840
Model 77: [0.2059076875448227, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1805 - accuracy: 1.00008/8 [==============================] - 0s 314us/step - loss: 0.2057 - accuracy: 0.9840
Model 78: [0.2056969851255417, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1815 - accuracy: 1.00008/8 [==============================] - 0s 305us/step - loss: 0.2058 - accuracy: 0.9840
Model 79: [0.20578061044216156, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1804 - accuracy: 1.00008/8 [==============================] - 0s 320us/step - loss: 0.2057 - accuracy: 0.9840
Model 80: [0.20573127269744873, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1810 - accuracy: 1.00008/8 [==============================] - 0s 302us/step - loss: 0.2057 - accuracy: 0.9840
Model 81: [0.20565932989120483, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1803 - accuracy: 1.00008/8 [==============================] - 0s 311us/step - loss: 0.2059 - accuracy: 0.9840
Model 82: [0.20589232444763184, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1801 - accuracy: 1.00008/8 [==============================] - 0s 299us/step - loss: 0.2058 - accuracy: 0.9840
Model 83: [0.20581302046775818, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1807 - accuracy: 1.00008/8 [==============================] - 0s 306us/step - loss: 0.2059 - accuracy: 0.9840
Model 84: [0.20586837828159332, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1805 - accuracy: 1.00008/8 [==============================] - 0s 307us/step - loss: 0.2059 - accuracy: 0.9840
Model 85: [0.20588043332099915, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1810 - accuracy: 1.00008/8 [==============================] - 0s 311us/step - loss: 0.2058 - accuracy: 0.9840
Model 86: [0.20576654374599457, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1803 - accuracy: 1.00008/8 [==============================] - 0s 326us/step - loss: 0.2056 - accuracy: 0.9840
Model 87: [0.2055664211511612, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1801 - accuracy: 1.00008/8 [==============================] - 0s 303us/step - loss: 0.2056 - accuracy: 0.9840
Model 88: [0.20560096204280853, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1803 - accuracy: 1.00008/8 [==============================] - 0s 315us/step - loss: 0.2056 - accuracy: 0.9840
Model 89: [0.2055937796831131, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1803 - accuracy: 1.00008/8 [==============================] - 0s 296us/step - loss: 0.2058 - accuracy: 0.9840
Model 90: [0.20577558875083923, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1803 - accuracy: 1.00008/8 [==============================] - 0s 301us/step - loss: 0.2055 - accuracy: 0.9840
Model 91: [0.20554116368293762, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1810 - accuracy: 1.00008/8 [==============================] - 0s 304us/step - loss: 0.2061 - accuracy: 0.9840
Model 92: [0.20608863234519958, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1801 - accuracy: 1.00008/8 [==============================] - 0s 280us/step - loss: 0.2055 - accuracy: 0.9840
Model 93: [0.20554301142692566, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1803 - accuracy: 1.00008/8 [==============================] - 0s 312us/step - loss: 0.2055 - accuracy: 0.9840
Model 94: [0.20550939440727234, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1810 - accuracy: 1.00008/8 [==============================] - 0s 293us/step - loss: 0.2057 - accuracy: 0.9840
Model 95: [0.20569846034049988, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1799 - accuracy: 1.00008/8 [==============================] - 0s 295us/step - loss: 0.2056 - accuracy: 0.9840
Model 96: [0.20558986067771912, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1798 - accuracy: 1.00008/8 [==============================] - 0s 310us/step - loss: 0.2058 - accuracy: 0.9840
Model 97: [0.20578745007514954, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1798 - accuracy: 1.00008/8 [==============================] - 0s 298us/step - loss: 0.2055 - accuracy: 0.9840
Model 98: [0.20551885664463043, 0.984000027179718]
1/8 [==>...........................] - ETA: 0s - loss: 0.1804 - accuracy: 1.00008/8 [==============================] - 0s 306us/step - loss: 0.2057 - accuracy: 0.9840
Model 99: [0.2057407796382904, 0.984000027179718]
[SAVED TO all_outputs.txt] Gradient Descent Over!  Avg Score: 0.22156298622488976 Deviation: 0.03965603543159836 Best: 0.20550939440727234 Worst: 0.5094572305679321
[SAVED TO all_outputs.txt] Avg Accuracy: 0.9811200243234635 Deviation: 0.016810285091765607 Best: 0.828000009059906 Worst: 0.9879999756813049
[SAVED TO all_outputs.txt] Saved Figure as "[4]sgd_gradient_descent1_pop15_time500_avg100.png"
[SAVED TO all_outputs.txt] Saved Figure as "[5]sgd_test_result{sgdcount}.png"
[SAVED TO all_outputs.txt] Raw kwargs: {'total_a': 3.4, 'a1_percent': 0.5, 'epsilon': -0.21, 'population_size': 20, 'time_steps': 1000, 'a3': 0.0}
[SAVED TO all_outputs.txt] ARGS:  {'w': 0.5021822170828449, 'a1': 1.7, 'a2': 1.7, 'a3': 0.0, 'population_size': 20, 'time_steps': 1000, 'search_range': 1000, 'constrainer': <function run_script.<locals>.<lambda> at 0x7fe5af1314c0>}
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_2 (Dense)              (250, 8)                  56        
_________________________________________________________________
re_lu_1 (ReLU)               (250, 8)                  0         
_________________________________________________________________
dense_3 (Dense)              (250, 1)                  9         
=================================================================
Total params: 65
Trainable params: 65
Non-trainable params: 0
_________________________________________________________________
[SAVED TO all_outputs.txt] PSO 1 Training for 1000 Epochs with Population 20
init
Time:     49,  Best Fitness:       0.622454
Best Pos: [ -134.23857132   890.58659403  -645.72657178  -363.45318759
   360.92480979  -214.69136292  -337.13782956   224.78168434
   862.8316247   -551.39866914   213.1904877    272.98058234
    26.80920187    30.83883145   420.49682062  -307.54133899
   126.08657442   -35.28622272  -670.01004581   203.328613
  -695.90626966  -100.50423867  -131.64794742  -882.87105988
   127.4241341   -620.17222515  -578.75907389   294.55067757
    80.01414351  -383.07652339   549.70599658  -150.24243273
    34.32310897   489.65005811  -693.84876183  -185.8554625
   -13.02261871   207.45360515   239.51967698     7.04010054
   295.65392448    16.1547334    -43.33098981  -309.62596489
   804.96028118   348.07438628    17.6074617   -457.79639515
  -399.48516243  -979.44672198   754.90071818  1221.19345087
   890.44633776  -843.79241054  -143.41019644  -326.75025992
  -536.70123682  -160.22283281 -1458.9939282    189.42399987
   351.54986764   -78.84810335   -14.72946417   651.28898323
   -81.55580141]

Time:     99,  Best Fitness:       0.612736
Best Pos: [ -135.01581948   888.43269157 -1349.08648646   -64.58124185
   359.94925935  -215.49516618  -337.19262661   224.77675612
   863.56279873  -551.42207977   214.15304628   274.35102965
    27.07282187    30.07906362   418.22645994  -308.94080122
   123.63021199   -36.07685201  -976.23003775   204.69759592
  -696.39791715   -98.85482493  -131.25445863  -882.96049606
   125.57700979  -620.01552838  -580.11514684   291.48066285
    78.35756774  -383.46835819   549.62711043  -150.81908038
    52.98479796   486.51084523  -692.47847707  -184.9849223
   -12.6191859    206.87800839   239.101238       6.01082381
   295.83769914    18.75863259   348.95519761  -310.8705808
   805.08365951   345.14239467    16.39832505  -458.94834244
  -399.6859806   -980.23270003   752.8208993   1222.08544455
   890.0640352   -844.05730149  -144.19630649  -324.8911888
  -542.84302243  -159.81386044 -1459.89531717   201.3174489
   353.13802025   -79.85948349   -15.47656332   652.40521502
   -78.85719661]

Time:    149,  Best Fitness:       0.598302
Best Pos: [ -135.91214483   887.57074233 -1363.8952539    -64.61602848
   357.77754341  -215.52195019  -335.65044307   225.00800621
   862.75932637  -551.68114205   369.91354748   273.64710834
    26.86757106    29.71926174   417.44365807  -310.68921781
   128.52034282   -36.1832504   -976.88178476   206.52785025
  -247.85432345   -98.83319226  -130.4241295   -882.89508137
   122.71105019  -619.73983248  -579.93166025   290.99411898
    79.46685893  -384.33072434   550.30833591  -151.69935021
   840.74750147   486.79042309  -691.1400976   -185.08817623
   -12.95099161   206.54433921   240.27936455     5.47427047
   296.43350782    20.71009352   364.88827344  -310.09974322
   806.69803729   339.65526233    17.49283705  -458.38750889
  -400.21696849  -978.67418934   750.82974196  1222.42368318
   859.7456434   -845.55620755  -145.12074686  -324.70338348
  -543.08563231  -158.58718873 -1460.710393     217.17036661
   353.5175791    -80.77943828   -71.0835341    652.92429734
   -75.92532118]

Time:    199,  Best Fitness:       0.588080
Best Pos: [ -135.55351645   887.13086641 -1363.15910404   -64.58729751
   355.12672374  -217.27297254  -335.14598516   224.85454454
   862.39266187  -551.47026328   370.68385502   272.49991396
    27.38769175    28.29200017   417.14770812  -311.22390748
   128.45547674   -35.13112694  -977.38889126   210.14032961
  -166.90552854   -97.9450814   -125.27198575  -883.99680769
    83.9440785   -620.32613921  -579.39332457    42.17103462
    92.91947262  -383.78398928   550.26714754  -152.79514243
   842.15136263   486.89289916  -689.25673409  -185.94683441
   -14.20146024   206.87875791   238.68188345     4.96851873
   297.43235518    21.05330675   365.76128596  -310.12704533
   808.22176778   337.44933725    18.12293266  -460.36190487
  -400.63249581  -978.4230705    748.0107554   1222.46653163
   243.74292107  -846.41485252  -146.42273565  -322.71705752
  -543.82320499  -158.9061355  -1461.40591562   254.16127171
   752.24393064   -84.90395875   -68.97987429   653.63996744
   -74.58568451]

Time:    249,  Best Fitness:       0.567817
Best Pos: [   -8.22708268   885.59756709 -1364.2519056    -64.11171357
   353.28693996  -217.28625585  -335.97956137   224.65824327
   862.02430077  -551.91253478   371.56740425   273.19773741
   204.76363768    27.59315417   416.09753913  -312.08267703
   128.10976527   -35.10468809  -976.70111029   209.80438981
  -166.91999854   -97.15952025  -127.03174295  -883.51714085
    83.33875922  -619.31103668  -579.76067767  -157.17874055
    97.00918818  -383.45237532   550.31920398  -153.1268635
   843.83681127   487.51676727  -688.1662716   -186.34444884
   -14.78298615   207.28773839   238.90061534     3.77231973
   297.84930022    23.96785854   365.67837509  -309.83065308
   810.07472628   334.84096824    19.32131416  -460.86701131
  -401.04957868  -977.74657983   746.54608669  1223.33138844
   243.77502999  -847.36354368  -147.25922721  -321.13797487
  -781.12862315  -157.70807856 -1465.41274771   337.63483699
   752.0677298    -85.042674      52.01444137   653.9233079
   -58.19528444]

Time:    299,  Best Fitness:       0.556151
Best Pos: [   -8.62987998   884.82123502 -1364.03670306   -62.56422954
   351.46670564  -218.17814858  -336.32875671   225.25764618
   861.62808747  -552.23569791   373.91571268   273.39730116
   205.33373965    26.71233738   415.95666091  -312.58777279
   138.05817605   -35.25095717  -977.65491416   111.77818848
   -28.69927448   -96.79390356  -130.7503916   -883.96697237
    29.01768204  -619.21066508  -578.78090182  -159.91759222
   120.17002301  -382.48589957   549.66961759  -154.5938404
   845.16324804   488.415163    -686.91706312  -186.59623824
   -14.78370451   207.05445532   238.89736902     3.0060484
   298.13948182    25.6277029    366.81005175  -309.92472254
   811.51919265   332.17929441    20.59078385  -461.57931114
  -401.59114445  -978.30814132   745.57827797  1224.1461985
   243.56680772  -848.27116477  -148.14043818  -320.09068818
 -1067.1470475   -158.28100433 -1466.80172973   456.26834147
   751.92318311   -85.48343149    50.14134092   654.17093608
   -56.51107622]

Time:    349,  Best Fitness:       0.549820
Best Pos: [   -9.26771878   882.99976237 -1365.20128374   -62.19652532
   349.41545879  -218.95269799  -335.75151875   224.89117532
   957.2944144   -548.91939236   375.28658361   272.93238162
   205.21268844    26.34171918   414.82860212  -313.77718614
   147.75469111   -36.16831912  -977.18721997   111.25406819
   -27.94870723   -96.00357493  -131.78545552  -885.06318874
    20.34204497  -620.02287498  -578.37884454  -145.99776113
   119.65127582  -382.38207365   206.90437942   -88.48731753
   845.7893932    488.18196088  -686.13737282  -188.30159712
   -15.42800886   206.95220826   238.55057383     2.85951484
   298.04293768    26.65768672   367.50899859  -310.4519016
   812.59118785   330.17191174    21.89030015  -462.75219016
  -546.85594559  -977.57461051   745.04611317  1225.06066799
   242.26755186  -849.93844647  -150.01475403  -318.41508383
 -1067.35081838  -157.62326167 -1468.29243678   458.32826796
   751.79694546   -85.99981352    51.77092285   655.94495148
   -54.34114002]

Time:    399,  Best Fitness:       0.536881
Best Pos: [   45.99097735   880.411314   -1366.56465866   -61.93226179
   345.31335784  -220.43658139  -334.95723837   224.59269966
   977.99511782  -548.86178186   375.99964277   271.04488078
   204.79528734    26.23709965   414.09506432  -324.32356304
   168.06975399   -32.80515264  -976.84456252   112.43947729
    -4.52154597   -97.28184853  -132.80850427  -884.0393055
    14.23561423  -619.79557004  -579.31459816  -147.49149619
   126.024303    -381.18374208   195.85720787   -91.35948182
   847.06242492   487.93094358  -684.6336924   -189.22691542
   -15.7583574    206.68396311   238.09231075     2.29336934
   298.10943927    27.54207703   368.20760292  -309.79891913
  1041.76973713   327.81997019    22.42600973  -464.16332971
  -547.25961132  -977.96660976   745.04536902  1225.66146016
   241.1813239   -851.62259055  -151.41054551  -317.52446408
 -1067.76597349  -156.37498765 -2044.12822748   519.71025839
   751.90755681   -86.24668228    54.19988382   654.76376401
   -65.93538978]

Time:    449,  Best Fitness:       0.529864
Best Pos: [ 4.60722252e+01  8.78809495e+02 -1.36868935e+03 -1.48452353e+02
  3.42614090e+02 -2.19440561e+02 -3.34013600e+02  2.25045829e+02
  1.13870972e+03 -5.48411402e+02  3.75564887e+02  2.70829837e+02
  2.05082770e+02  2.48314185e+01  4.12862735e+02 -3.23772689e+02
  1.82081878e+02 -3.35733643e+01 -9.75886157e+02  1.13503557e+02
  9.81342919e+00 -9.74726143e+01 -1.32841785e+02 -8.85237123e+02
  3.98872300e+00 -6.20328560e+02 -5.51061788e+02 -1.48779133e+02
  1.24089199e+02 -3.80434229e+02  1.96433987e+02 -9.27056280e+01
  8.47983250e+02  4.90379957e+02 -6.83341381e+02 -4.57872724e+02
 -1.61054521e+01  2.06952317e+02  2.37270193e+02  2.07416519e+00
  2.97136838e+02  2.86821436e+01  3.66965742e+02 -3.09834492e+02
  1.04431261e+03  3.25733924e+02  2.34857299e+01 -4.64676928e+02
 -5.47911503e+02 -9.79042729e+02  7.42049707e+02  1.23209832e+03
  2.41841819e+02 -8.52064190e+02 -1.51496955e+02 -3.17496361e+02
 -1.06896507e+03 -1.56667973e+02 -2.09190079e+03  5.23032606e+02
  9.22465336e+02 -8.75540955e+01  5.61462602e+01  6.55219748e+02
 -6.37407029e+01]

Time:    499,  Best Fitness:       0.526017
Best Pos: [ 6.10030911e+01  8.77889459e+02 -1.37002791e+03 -1.48175510e+02
  3.26686324e+02 -2.19211811e+02 -3.33453943e+02  2.25363114e+02
  1.13783827e+03 -5.48487858e+02  3.76550421e+02  2.72470154e+02
  2.83114474e+02  2.32187471e+01  4.16231475e+02 -3.24021537e+02
  1.84428308e+02 -3.37100405e+01 -9.75726055e+02  1.14079976e+02
  3.24524042e+01 -9.78564477e+01 -1.33197213e+02 -8.86133345e+02
 -5.80178823e+00 -6.18804246e+02 -5.51664683e+02 -1.56176786e+02
  1.38502406e+02 -3.79244120e+02  1.96441450e+02 -9.27616836e+01
  8.48099477e+02  4.90832870e+02 -6.81624613e+02 -4.62661116e+02
 -1.60759202e+01  2.06859234e+02  2.37271549e+02  1.19555185e+00
  2.97905607e+02  2.95140744e+01  3.66469486e+02 -3.09785176e+02
  1.04606978e+03  3.23669712e+02  2.55957070e+01 -4.65297827e+02
 -5.48220121e+02 -9.79983809e+02  7.39809508e+02  1.23374648e+03
  2.44576567e+02 -8.52345357e+02 -1.52701573e+02 -3.13923498e+02
 -1.23298435e+03 -1.55591811e+02 -2.09213925e+03  5.24697566e+02
  9.25890375e+02 -8.74162904e+01  5.83840466e+01  6.55397178e+02
 -6.19698584e+01]

Time:    549,  Best Fitness:       0.519367
Best Pos: [ 9.75469278e+01  8.76015812e+02 -1.37099595e+03 -1.48549253e+02
  3.25267309e+02 -2.18685301e+02 -3.33223007e+02  2.24835242e+02
  1.13737208e+03 -5.48343848e+02  3.77421651e+02  2.72603576e+02
  2.98971301e+02  2.25029904e+01  4.13456455e+02 -3.25608781e+02
  1.79730688e+02 -3.33935425e+01 -9.75272962e+02  1.14653756e+02
  3.66420214e+01 -9.78634423e+01 -1.33701955e+02 -8.88276689e+02
 -7.20730670e+00 -6.19843592e+02 -5.24053327e+02 -1.57186956e+02
  1.30051884e+02 -3.74247019e+02  1.97135838e+02 -9.47177028e+01
  8.46960468e+02  4.91290080e+02 -6.80013665e+02 -4.62289699e+02
 -1.60931541e+01  2.06977550e+02  2.38263277e+02 -5.00775215e-01
  2.99103846e+02  2.97493639e+01  3.66239191e+02 -3.08907701e+02
  1.04747791e+03  3.21143827e+02  2.67006236e+01 -4.66543118e+02
 -5.48363050e+02 -9.78215227e+02  7.36541889e+02  1.23502312e+03
  2.45005092e+02 -8.53869750e+02 -1.53495533e+02 -3.12627900e+02
 -1.49468848e+03 -1.54623647e+02 -2.09303388e+03  5.25791596e+02
  1.24563824e+03 -8.80210467e+01  5.96769829e+01  6.56387417e+02
 -6.01557023e+01]

Time:    599,  Best Fitness:       0.515838
Best Pos: [ 8.33998155e+01  8.75086075e+02 -1.37157901e+03 -1.48402264e+02
  3.23290337e+02 -2.18857282e+02 -3.33409756e+02  2.25121436e+02
  1.16747096e+03 -5.48273378e+02  3.78436700e+02  2.94408915e+02
  2.97451963e+02  2.21773083e+01  4.12317740e+02 -3.29968454e+02
  1.65347976e+02  8.44321385e+01 -9.75366353e+02  3.99593905e+01
  6.03266394e+01 -9.75291215e+01 -1.34754001e+02 -8.87249865e+02
 -6.50286604e+00 -6.19338313e+02 -5.21816425e+02 -1.58607081e+02
  1.30524281e+02 -3.73425593e+02  1.96414413e+02 -9.50456042e+01
  8.47627205e+02  4.91799901e+02 -6.78705102e+02 -4.62544059e+02
 -1.55246863e+01  2.06349568e+02  2.37704308e+02 -9.55704088e-01
  3.00580364e+02  3.13268721e+01  3.66420717e+02 -3.08654655e+02
  1.04943929e+03  3.19554808e+02  2.82533742e+01 -4.68377146e+02
 -5.92325310e+02 -9.78335682e+02  7.34912717e+02  1.23662798e+03
  2.46868775e+02 -8.56067846e+02 -1.55281003e+02 -3.11989177e+02
 -1.49516250e+03 -1.53674579e+02 -2.27395853e+03  5.27097974e+02
  1.24606078e+03 -8.85228936e+01  6.06329465e+01  6.56554517e+02
 -5.73717958e+01]

Time:    649,  Best Fitness:       0.512185
Best Pos: [ 8.34380302e+01  8.73822136e+02 -1.37212742e+03 -9.57022508e+01
  3.20644696e+02 -2.19430555e+02 -3.33288453e+02  2.24924253e+02
  1.20540711e+03 -5.47581814e+02  3.78679030e+02  2.94835474e+02
  2.97329494e+02  2.12498092e+01  4.10365100e+02 -3.28516645e+02
  1.77688513e+02  8.38125604e+01 -9.75395054e+02  4.06456460e+01
  5.96331602e+01 -9.73082222e+01 -1.35346660e+02 -8.87753319e+02
 -1.40371795e+01 -6.15931664e+02 -5.22368365e+02 -1.64956844e+02
  1.32208779e+02 -3.73297048e+02  1.96816991e+02 -9.61159965e+01
  8.48386655e+02  4.93813098e+02 -6.75741595e+02 -4.60795498e+02
 -1.64572522e+01  2.07199637e+02  2.37949488e+02 -5.96926456e-01
  3.03588363e+02  3.24596096e+01  3.66537059e+02 -3.08513198e+02
  1.05171679e+03  3.17479531e+02  2.91673880e+01 -4.69390180e+02
 -5.91326204e+02 -9.77581802e+02  7.33430184e+02  1.23661434e+03
  2.45941660e+02 -8.56799930e+02 -1.55615905e+02 -3.09998954e+02
 -1.49670038e+03 -1.53130580e+02 -2.27446802e+03  7.03608854e+02
  1.24611394e+03 -8.91785876e+01  6.29444584e+01  6.56170733e+02
 -5.57789863e+01]

Time:    699,  Best Fitness:       0.504937
Best Pos: [ 8.38935266e+01  8.71874542e+02 -1.37451122e+03 -9.37338306e+01
  3.19150827e+02 -2.20845021e+02 -3.33833030e+02  2.24471193e+02
  1.20507819e+03 -5.47946177e+02  3.74053774e+02  2.95017203e+02
  2.96770265e+02  2.12987220e+01  4.09918016e+02 -3.29374501e+02
  1.39106238e+02  8.37264737e+01 -1.05709384e+03 -2.52580781e+01
  5.95391181e+01 -9.71407731e+01 -1.36352522e+02 -8.88521907e+02
 -1.39146277e+01 -6.15980391e+02 -5.23543133e+02 -1.65170458e+02
  1.32379079e+02 -3.73294982e+02  1.98163530e+02 -9.65506849e+01
  8.48140013e+02  4.93550480e+02 -6.74214443e+02 -4.60053336e+02
 -1.51265764e+01  2.07356707e+02  2.37679178e+02 -1.51378331e+00
  4.59160402e+02  3.27406895e+01  3.67690052e+02 -3.09172500e+02
  1.05224711e+03  3.16195178e+02  3.02466065e+01 -4.70086144e+02
 -5.92344398e+02 -9.77612935e+02  8.65241547e+02  1.23663612e+03
  2.46826163e+02 -8.58272605e+02 -1.56278793e+02 -3.07802491e+02
 -1.49531116e+03 -1.53637664e+02 -2.27649370e+03  7.86156331e+02
  1.24626888e+03 -8.98043248e+01  6.48442782e+01  6.58436755e+02
 -5.39418144e+01]

Time:    749,  Best Fitness:       0.474481
Best Pos: [ 1.25666946e+02  8.71198767e+02 -1.37586856e+03 -9.57660730e+01
  3.17499848e+02 -2.20736446e+02 -3.34352285e+02  2.24032049e+02
  1.20403181e+03 -5.45976255e+02  3.73957295e+02  2.06176725e+02
  2.96001570e+02  2.00049871e+01  4.09359614e+02 -3.29400012e+02
  1.25840167e+02  8.37116703e+01 -1.05621835e+03 -1.38363060e+02
  6.89435790e+01 -9.68636958e+01 -1.36968213e+02 -8.88626142e+02
 -1.11543234e+01 -6.16809614e+02 -5.24291469e+02 -1.60874485e+02
  1.30881711e+02 -3.73249436e+02  1.96754120e+02 -9.78176477e+01
  8.48140870e+02  4.92893100e+02 -6.72381530e+02 -4.60140525e+02
 -1.47515432e+01  2.07271405e+02  2.37827738e+02 -1.50977332e+00
  4.55974096e+02  3.45835735e+01  3.67684589e+02 -3.09229264e+02
  1.05287576e+03  3.13848094e+02  3.16886101e+01 -4.71783866e+02
 -5.93490034e+02 -9.78445763e+02  8.62342780e+02  1.23784800e+03
  2.46811585e+02 -8.57963261e+02 -1.57808939e+02 -3.05032548e+02
 -1.49508460e+03 -2.84307221e+02 -2.27921131e+03  1.25296158e+03
  1.25909557e+03 -9.00124960e+01  6.50502951e+01  6.58815559e+02
 -5.19257826e+01]

Time:    799,  Best Fitness:       0.467669
Best Pos: [  124.93133891   870.43041224 -1377.86900104   -95.84558569
   356.50189138  -221.21593672  -333.60172177   223.78419495
  1203.35389095  -545.28732541   373.92751795   202.21262154
   295.34623285    19.19237945   407.77360564  -331.03330609
   125.95005534    82.33800849 -1206.12672082  -141.31433722
    75.16793201   -96.51680321  -135.02441009  -889.3044497
    -8.70798916  -618.52789385  -486.4526949   -160.53998109
   126.51790059  -371.28717694   195.21656771   -99.45619139
   848.68902109   494.19372723  -671.49320809  -460.35739386
   -16.6437613    208.24174926   237.96531982    -2.29855041
   457.81486428    34.81458001   368.36497406  -309.80069346
  1053.4334582    310.58973703    33.26623689  -471.74138389
  -594.88428686  -978.8241056   1102.53641774  1239.04835683
   245.15373778  -860.10592716  -158.45405511  -303.26220528
 -1495.62055804  -283.90319643 -2282.02698753  1255.49667347
  1259.45592991   -90.654958      66.78669455   660.72244189
   -50.84525615]

Time:    849,  Best Fitness:       0.462055
Best Pos: [  125.83852796   868.46160655 -1379.1877065   -156.3317429
   355.46593797  -222.0670209   -332.36688225   224.09854531
  1203.45777242  -544.34713885   374.92253354   205.32204799
   295.07655692    19.0219559    408.09189084  -330.16033273
   131.8498775     81.75174758 -1206.86738732  -194.56597221
    79.24248201   -97.05207071  -134.58667399  -888.3296988
    -8.20805568  -619.52952337  -488.01091177  -176.37453458
   126.50413164  -371.73417392   196.93327724  -100.95763075
   848.30039391   496.90439167  -670.20104525  -460.49722384
   -16.95329571   208.52989372   238.06423645    -2.88985325
   458.5922192     35.74409021   369.06582671  -310.32983629
  1054.51434333   308.37040129    34.0112351   -474.02987136
  -596.0494398   -978.18970254  1118.48605045  1478.25565397
   245.62786861  -862.07349158  -159.87809366  -196.60207959
 -1493.57997007  -283.80255176 -2284.68886683  1256.6986095
  1258.65755017   -91.23740232    64.95643903   661.49531893
   -49.33235753]

Time:    899,  Best Fitness:       0.449647
Best Pos: [  125.88846295   867.64322983 -1381.59023116  -157.61600946
   353.88425958  -222.47635482  -331.01779468   224.6860691
  1202.84639124  -543.74667019   375.11091833   214.43011862
   293.80745758    20.00819674   407.34881654  -300.66430861
   123.92856546    81.4646704  -1206.29169765  -193.39358871
    79.56836964   -96.26686606  -133.88785752  -888.45384927
   -10.22978117  -620.04845791  -488.66032566  -176.36757212
   139.28777656  -370.99728768   194.77463962  -102.45806915
   846.95895042   496.90829772  -667.82884357  -460.27617721
   -18.99498278   209.03884503   238.10222232    -3.12053648
   458.91047967    35.6528198    370.08045179  -310.29901693
  1055.39640785   305.93643231    32.70651257  -472.93507993
  -598.94022307  -978.39420827  1116.91972943  1479.73732225
   247.79377452  -864.5194864   -159.73662015  -185.36773154
 -1493.67488498  -281.79177782 -2286.83905024  1631.90559927
  1334.93146403   -93.00560823    68.61024329   664.48003099
  -550.86236006]

Time:    949,  Best Fitness:       0.437347
Best Pos: [  126.21439715   866.38800697 -1384.00307999  -157.0709162
   352.27089931  -225.54500296  -331.81164019   224.70737644
  1201.54161829  -542.62016904   375.12588391   215.23268324
   293.47915085    18.70649308   406.87962458  -300.83709291
   123.69702497    80.94697873 -1325.27714976  -189.88271403
    89.51868715   -95.90402871  -134.41561696  -889.26232586
    -2.41824007  -619.01378273  -492.28020801  -182.53810814
   137.46337627  -371.48173635   171.52905462  -103.49032859
   847.03527118   491.43754167  -666.27797334  -351.52676943
   -19.80248581   208.49434842   237.91500772    -3.60535873
   450.64206417    35.57225605   370.68020782  -430.79935629
  1055.52313054   304.60278873    34.97789425  -474.03076361
  -598.10448142  -978.49879749  1484.80071158  1481.46620269
   248.23706504  -869.11532095  -160.62043034  -183.65765879
 -1493.33669689  -279.74140254 -2288.02432421  2133.2834143
  1341.98907881   -93.93127993   146.05272897   664.62900497
  -673.24221294]

Time:    999,  Best Fitness:       0.433702
Best Pos: [  151.62511362   862.23400119 -1385.34952535  -157.22706119
   349.14892929  -226.03322224  -330.96010771   224.51024633
  1202.31168653  -543.18143987   377.31619115   246.99221437
   292.54463483    17.38958716   406.45244284  -301.59949188
   124.46074637    79.82659125 -1322.513413    -197.40317181
    94.42451365   -94.96109063  -134.43450209  -890.03481984
     3.77644225  -619.49566104  -518.0135669   -183.73810228
   137.02251514  -370.79574447   172.66044172  -104.34728601
   845.5191225    491.62918455  -667.03805157  -346.01722105
   -19.26550551   208.67980305   238.32401464    -4.51598517
   451.39911369    36.29916057   372.06597991  -542.25272888
  1056.73425731   302.10821339    35.41096477  -474.09053852
  -598.41290163  -977.90319571  1483.34949702  1483.29096182
   249.2262616   -870.55494082  -162.35620336  -179.5157755
 -1492.9605463   -278.44004611 -2291.87176966  2133.24538506
  1342.09341472   -95.44450167   148.6141227    664.99822773
  -671.57929539]

1/8 [==>...........................] - ETA: 0s - loss: 0.7412 - accuracy: 0.71888/8 [==============================] - 0s 323us/step - loss: 0.5557 - accuracy: 0.8080
[SAVED TO all_outputs.txt] PSO Training Over!  Score: [0.5557091236114502, 0.8080000281333923]
[SAVED TO all_outputs.txt] Saved Figure as "[6]pso1.png"
[SAVED TO all_outputs.txt] ARGS:  {'population_size': 10, 'time_steps': 50, 'mutation_rate': 0.1, 'crossover_rate': 0.5, 'train_epochs': 100, 'test_epochs': 500, 'batch': 5}
[SAVED TO all_outputs.txt] GA 1 Training for 50 Generations with Population 10
1/50: Best Fitness 0.4977352023124695
3/50: Best Fitness 0.29672348499298096
5/50: Best Fitness 0.29287371039390564
7/50: Best Fitness 0.29287371039390564
9/50: Best Fitness 0.29287371039390564
11/50: Best Fitness 0.29287371039390564
13/50: Best Fitness 0.29287371039390564
15/50: Best Fitness 0.29287371039390564
17/50: Best Fitness 0.29287371039390564
19/50: Best Fitness 0.29287371039390564
21/50: Best Fitness 0.29287371039390564
23/50: Best Fitness 0.29287371039390564
25/50: Best Fitness 0.29287371039390564
27/50: Best Fitness 0.29287371039390564
29/50: Best Fitness 0.29287371039390564
31/50: Best Fitness 0.29287371039390564
33/50: Best Fitness 0.29169178009033203
35/50: Best Fitness 0.29169178009033203
37/50: Best Fitness 0.29169178009033203
39/50: Best Fitness 0.29169178009033203
41/50: Best Fitness 0.29169178009033203
43/50: Best Fitness 0.29169178009033203
45/50: Best Fitness 0.2854066491127014
47/50: Best Fitness 0.2854066491127014
49/50: Best Fitness 0.2854066491127014
50/50: Best Fitness 0.2854066491127014
Model: "sequential_513"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1839 (Dense)           (None, 5)                 35        
_________________________________________________________________
re_lu_1326 (ReLU)            (None, 5)                 0         
_________________________________________________________________
dense_1840 (Dense)           (None, 15)                90        
_________________________________________________________________
re_lu_1327 (ReLU)            (None, 15)                0         
_________________________________________________________________
dense_1841 (Dense)           (None, 16)                256       
_________________________________________________________________
re_lu_1328 (ReLU)            (None, 16)                0         
_________________________________________________________________
dense_1842 (Dense)           (None, 1)                 17        
=================================================================
Total params: 398
Trainable params: 398
Non-trainable params: 0
_________________________________________________________________
1/8 [==>...........................] - ETA: 0s - loss: 0.1683 - accuracy: 1.00008/8 [==============================] - 0s 382us/step - loss: 0.1833 - accuracy: 0.9800
[SAVED TO all_outputs.txt] GA Best (with genotype 1 010 Normal,1 111 Normal,0 101 HeNormal,0 011 HeNormal,1 111 HeNormal):  [0.18328481912612915, 0.9800000190734863]
[SAVED TO all_outputs.txt] Saved Figure as "[7]plot_of_ga_accuracies_over_time.png"
[SAVED TO all_outputs.txt] Saved Figure as "[8]ga1.png"
[SAVED TO all_outputs.txt] ARGS:  {'population_size': 10, 'time_steps': 50, 'mutation_rate': 0.5, 'crossover_rate': 0.1, 'flip_chance': 0.5, 'whither_rate': 0.1, 'growth_rate': 0.1, 'train_epochs': 100, 'test_epochs': 500, 'batch': 5}
[SAVED TO all_outputs.txt] GP 1 Training for 50 Generations with Population 10
1/50: Best Fitness 0.6224079728126526
3/50: Best Fitness 0.6224079728126526
5/50: Best Fitness 0.562694251537323
7/50: Best Fitness 0.562694251537323
9/50: Best Fitness 0.562694251537323
11/50: Best Fitness 0.3767227828502655
13/50: Best Fitness 0.3767227828502655
15/50: Best Fitness 0.3767227828502655
17/50: Best Fitness 0.3767227828502655
19/50: Best Fitness 0.3767227828502655
21/50: Best Fitness 0.3767227828502655
23/50: Best Fitness 0.3767227828502655
25/50: Best Fitness 0.3767227828502655
27/50: Best Fitness 0.3373144268989563
29/50: Best Fitness 0.3373144268989563
31/50: Best Fitness 0.3373144268989563
33/50: Best Fitness 0.3373144268989563
35/50: Best Fitness 0.3373144268989563
37/50: Best Fitness 0.3373144268989563
39/50: Best Fitness 0.3373144268989563
41/50: Best Fitness 0.3373144268989563
43/50: Best Fitness 0.3373144268989563
45/50: Best Fitness 0.3373144268989563
47/50: Best Fitness 0.3373144268989563
49/50: Best Fitness 0.3373144268989563
50/50: Best Fitness 0.3373144268989563
Model: "functional_1023"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_512 (InputLayer)          [(None, 500, 6)]     0                                            
__________________________________________________________________________________________________
dense_5417 (Dense)              (None, 500, 6)       42          input_512[0][0]                  
__________________________________________________________________________________________________
dense_5418 (Dense)              (None, 500, 6)       42          input_512[0][0]                  
__________________________________________________________________________________________________
concatenate_1279 (Concatenate)  (None, 500, 12)      0           dense_5417[0][0]                 
                                                                 dense_5418[0][0]                 
__________________________________________________________________________________________________
dense_5419 (Dense)              (None, 500, 10)      130         concatenate_1279[0][0]           
__________________________________________________________________________________________________
re_lu_1972 (ReLU)               (None, 500, 10)      0           dense_5419[0][0]                 
__________________________________________________________________________________________________
dense_5420 (Dense)              (None, 500, 6)       42          input_512[0][0]                  
__________________________________________________________________________________________________
concatenate_1278 (Concatenate)  (None, 500, 16)      0           re_lu_1972[0][0]                 
                                                                 dense_5420[0][0]                 
__________________________________________________________________________________________________
dense_5421 (Dense)              (None, 500, 4)       68          concatenate_1278[0][0]           
__________________________________________________________________________________________________
activation_633 (Activation)     (None, 500, 4)       0           dense_5421[0][0]                 
__________________________________________________________________________________________________
dense_5422 (Dense)              (None, 500, 6)       42          input_512[0][0]                  
__________________________________________________________________________________________________
dense_5424 (Dense)              (None, 500, 6)       42          input_512[0][0]                  
__________________________________________________________________________________________________
dense_5425 (Dense)              (None, 500, 6)       42          input_512[0][0]                  
__________________________________________________________________________________________________
concatenate_1277 (Concatenate)  (None, 500, 10)      0           activation_633[0][0]             
                                                                 dense_5422[0][0]                 
__________________________________________________________________________________________________
concatenate_1280 (Concatenate)  (None, 500, 12)      0           dense_5424[0][0]                 
                                                                 dense_5425[0][0]                 
__________________________________________________________________________________________________
dense_5423 (Dense)              (None, 500, 4)       44          concatenate_1277[0][0]           
__________________________________________________________________________________________________
dense_5426 (Dense)              (None, 500, 2)       26          concatenate_1280[0][0]           
__________________________________________________________________________________________________
re_lu_1973 (ReLU)               (None, 500, 4)       0           dense_5423[0][0]                 
__________________________________________________________________________________________________
activation_634 (Activation)     (None, 500, 2)       0           dense_5426[0][0]                 
__________________________________________________________________________________________________
concatenate_1276 (Concatenate)  (None, 500, 6)       0           re_lu_1973[0][0]                 
                                                                 activation_634[0][0]             
__________________________________________________________________________________________________
dense_5427 (Dense)              (None, 500, 10)      70          concatenate_1276[0][0]           
__________________________________________________________________________________________________
activation_635 (Activation)     (None, 500, 10)      0           dense_5427[0][0]                 
__________________________________________________________________________________________________
dense_5428 (Dense)              (None, 500, 1)       11          activation_635[0][0]             
==================================================================================================
Total params: 601
Trainable params: 601
Non-trainable params: 0
__________________________________________________________________________________________________
1/8 [==>...........................] - ETA: 0s - loss: 0.4726 - accuracy: 0.93758/8 [==============================] - 0s 537us/step - loss: 0.4105 - accuracy: 0.9600
[SAVED TO all_outputs.txt] GP Best (binary_crossentropy, accuracy):  [0.41049492359161377, 0.9599999785423279] 
 With key: Linear[10, HeNormal]: (ReLU[4, HeNormal]: (Swish[4, Zeroes]: (ReLU[10, HeNormal]: (Input,Input),Input),Input),Linear[2, Normal]: (Input,Input))
[SAVED TO all_outputs.txt] Saved Figure as "[9]plot_of_gp_accuracies_over_time.png"
[SAVED TO all_outputs.txt] Saved Figure as "[10]gp1.png"
